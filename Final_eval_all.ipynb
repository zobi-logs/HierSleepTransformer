{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bd330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Visible CUDA devices: 1\n",
      "Using device: cuda\n",
      "GPU: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 0] Imports + GPU + device\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- choose GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"   # change if needed\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Visible CUDA devices:\", torch.cuda.device_count())\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3655ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 9868\n",
      "cohort  split        \n",
      "MESA    external_test    1856\n",
      "SHHS1   test              548\n",
      "        train            4380\n",
      "        val               548\n",
      "SHHS2   external_test    2536\n",
      "dtype: int64\n",
      "MESA detected | rows: 1856\n",
      "DF sizes: 4380 548 548 2536 | MESA=1856\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 1] Paths + Manifest split (same)\n",
    "ROOT = Path(\"/data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/\")\n",
    "MANIFEST_PATH = ROOT / \"manifest_sleepstaging_planA.csv\"\n",
    "assert MANIFEST_PATH.exists(), f\"Missing manifest: {MANIFEST_PATH}\"\n",
    "\n",
    "manifest = pd.read_csv(MANIFEST_PATH)\n",
    "print(\"Rows:\", len(manifest))\n",
    "print(manifest.groupby([\"cohort\",\"split\"]).size())\n",
    "\n",
    "df_train = manifest[(manifest.cohort==\"SHHS1\") & (manifest.split==\"train\")].copy()\n",
    "df_val   = manifest[(manifest.cohort==\"SHHS1\") & (manifest.split==\"val\")].copy()\n",
    "df_test  = manifest[(manifest.cohort==\"SHHS1\") & (manifest.split==\"test\")].copy()\n",
    "df_ext   = manifest[(manifest.cohort==\"SHHS2\") & (manifest.split==\"external_test\")].copy()\n",
    "\n",
    "df_mesa = manifest[(manifest.cohort==\"MESA\")].copy() if (\"MESA\" in manifest[\"cohort\"].unique()) else None\n",
    "if df_mesa is not None and len(df_mesa) > 0:\n",
    "    if \"external_test\" in df_mesa[\"split\"].unique():\n",
    "        df_mesa = df_mesa[df_mesa.split==\"external_test\"].copy()\n",
    "    print(\"MESA detected | rows:\", len(df_mesa))\n",
    "else:\n",
    "    df_mesa = None\n",
    "    print(\"MESA not detected in manifest (ok).\")\n",
    "\n",
    "print(\"DF sizes:\", len(df_train), len(df_val), len(df_test), len(df_ext),\n",
    "      (\"| MESA=\"+str(len(df_mesa)) if df_mesa is not None else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7022688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenter + Normalizer ready (per-epoch z-score).\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 2] Augment + Normalize (identical)\n",
    "class EEGAugment:\n",
    "    def __init__(self,\n",
    "                 p_amp=0.5, p_noise=0.5, p_shift=0.5, p_bandstop=0.3, p_freqdrop=0.3,\n",
    "                 amp_range=(0.8, 1.2), noise_std=0.01, shift_max=125,\n",
    "                 bandstop_ranges=((49,51), (59,61)), freqdrop_max_bins=12):\n",
    "        self.p_amp = p_amp\n",
    "        self.p_noise = p_noise\n",
    "        self.p_shift = p_shift\n",
    "        self.p_bandstop = p_bandstop\n",
    "        self.p_freqdrop = p_freqdrop\n",
    "        self.amp_range = amp_range\n",
    "        self.noise_std = noise_std\n",
    "        self.shift_max = shift_max\n",
    "        self.bandstop_ranges = bandstop_ranges\n",
    "        self.freqdrop_max_bins = freqdrop_max_bins\n",
    "\n",
    "    def _amp_scale(self, x):\n",
    "        s = np.random.uniform(self.amp_range[0], self.amp_range[1])\n",
    "        return x * s\n",
    "\n",
    "    def _gaussian_noise(self, x):\n",
    "        std = np.std(x, axis=1, keepdims=True) + 1e-6\n",
    "        noise = np.random.randn(*x.shape).astype(np.float32) * (self.noise_std * std)\n",
    "        return x + noise\n",
    "\n",
    "    def _time_shift(self, x):\n",
    "        shift = np.random.randint(-self.shift_max, self.shift_max+1)\n",
    "        return np.roll(x, shift=shift, axis=1)\n",
    "\n",
    "    def _bandstop_fft(self, x, fs=125.0):\n",
    "        E, T_ = x.shape\n",
    "        X = np.fft.rfft(x, axis=1)\n",
    "        freqs = np.fft.rfftfreq(T_, d=1.0/fs)\n",
    "        for (f1, f2) in self.bandstop_ranges:\n",
    "            mask = (freqs >= f1) & (freqs <= f2)\n",
    "            X[:, mask] = 0.0\n",
    "        y = np.fft.irfft(X, n=T_, axis=1).astype(np.float32)\n",
    "        return y\n",
    "\n",
    "    def _freq_dropout(self, x):\n",
    "        E, T_ = x.shape\n",
    "        X = np.fft.rfft(x, axis=1)\n",
    "        Fbins = X.shape[1]\n",
    "        drop = np.random.randint(1, self.freqdrop_max_bins+1)\n",
    "        start = np.random.randint(0, max(1, Fbins - drop))\n",
    "        X[:, start:start+drop] = 0.0\n",
    "        y = np.fft.irfft(X, n=T_, axis=1).astype(np.float32)\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x, fs=125.0):\n",
    "        if np.random.rand() < self.p_amp:\n",
    "            x = self._amp_scale(x)\n",
    "        if np.random.rand() < self.p_noise:\n",
    "            x = self._gaussian_noise(x)\n",
    "        if np.random.rand() < self.p_shift:\n",
    "            x = self._time_shift(x)\n",
    "        if np.random.rand() < self.p_bandstop:\n",
    "            x = self._bandstop_fft(x, fs=fs)\n",
    "        if np.random.rand() < self.p_freqdrop:\n",
    "            x = self._freq_dropout(x)\n",
    "        return x\n",
    "\n",
    "def normalize_epochs_zscore(x, eps=1e-6, clip=10.0):\n",
    "    mu = np.mean(x, axis=1, keepdims=True)\n",
    "    sd = np.std(x, axis=1, keepdims=True) + eps\n",
    "    x = (x - mu) / sd\n",
    "    if clip is not None:\n",
    "        x = np.clip(x, -clip, clip)\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "augment = EEGAugment()\n",
    "print(\"Augmenter + Normalizer ready (per-epoch z-score).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80aac8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [CELL 3] Labels/constants + Dataset (identical)\n",
    "LABELS = {0:\"W\", 1:\"N1\", 2:\"N2\", 3:\"N3\", 4:\"REM\"}\n",
    "NUM_CLASSES = 5\n",
    "FS = 125\n",
    "T = 3750\n",
    "\n",
    "def _compute_runlength_remaining(y):\n",
    "    E = len(y)\n",
    "    rem = np.zeros((E,), dtype=np.int64)\n",
    "    t = 0\n",
    "    while t < E:\n",
    "        j = t\n",
    "        while j < E and y[j] == y[t]:\n",
    "            j += 1\n",
    "        for k in range(t, j):\n",
    "            rem[k] = (j - k)\n",
    "        t = j\n",
    "    return rem\n",
    "\n",
    "def _bucketize_remaining(rem, edges=(2, 5, 10, 20, 40, 80, 160)):\n",
    "    edges = np.array(edges, dtype=np.int64)\n",
    "    b = np.zeros_like(rem, dtype=np.int64)\n",
    "    for i, r in enumerate(rem):\n",
    "        b[i] = int(np.searchsorted(edges, r, side=\"right\"))\n",
    "    return b\n",
    "\n",
    "def _make_soft_targets_boundary(y, num_classes=5, radius=2, alpha_max=0.35):\n",
    "    E = len(y)\n",
    "    soft = np.zeros((E, num_classes), dtype=np.float32)\n",
    "    soft[np.arange(E), y] = 1.0\n",
    "\n",
    "    if E < 2 or radius <= 0:\n",
    "        return soft\n",
    "\n",
    "    trans = np.where(y[1:] != y[:-1])[0] + 1\n",
    "    if trans.size == 0:\n",
    "        return soft\n",
    "\n",
    "    for t in trans:\n",
    "        for dt in range(-radius, radius+1):\n",
    "            i = t + dt\n",
    "            if i < 0 or i >= E:\n",
    "                continue\n",
    "            dist = abs(dt)\n",
    "            if dist > radius:\n",
    "                continue\n",
    "            alpha = alpha_max * (1.0 - (dist / max(radius, 1)))\n",
    "            if alpha <= 0:\n",
    "                continue\n",
    "\n",
    "            if i < t:\n",
    "                nb = y[t]\n",
    "            else:\n",
    "                nb = y[t-1]\n",
    "\n",
    "            cur = y[i]\n",
    "            if nb == cur:\n",
    "                continue\n",
    "\n",
    "            soft[i, :] = 0.0\n",
    "            soft[i, cur] = 1.0 - alpha\n",
    "            soft[i, nb]  = alpha\n",
    "\n",
    "    soft = soft / (soft.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    return soft.astype(np.float32)\n",
    "\n",
    "class SleepSequenceDataset(Dataset):\n",
    "    def __init__(self, df, mode=\"train\",\n",
    "                 max_hours=None, min_hours=2.0,\n",
    "                 augmentor=None, exclude_unknown=True, do_normalize=True,\n",
    "                 boundary_oversample_p=0.70, boundary_radius=2,\n",
    "                 soft_radius=2, soft_alpha_max=0.35,\n",
    "                 dur_edges=(2,5,10,20,40,80,160)):\n",
    "        self.paths = df[\"npz_path\"].tolist()\n",
    "        self.mode = mode\n",
    "        self.max_hours = max_hours\n",
    "        self.min_hours = min_hours\n",
    "        self.augmentor = augmentor\n",
    "        self.exclude_unknown = exclude_unknown\n",
    "        self.do_normalize = do_normalize\n",
    "\n",
    "        self.boundary_oversample_p = boundary_oversample_p\n",
    "        self.boundary_radius = int(boundary_radius)\n",
    "\n",
    "        self.soft_radius = int(soft_radius)\n",
    "        self.soft_alpha_max = float(soft_alpha_max)\n",
    "        self.dur_edges = tuple(dur_edges)\n",
    "\n",
    "        print(f\"SleepSequenceDataset[{mode}] files={len(self.paths)} max_hours={self.max_hours} normalize={self.do_normalize}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def _pick_block_start_boundary_aware(self, y, L):\n",
    "        E = len(y)\n",
    "        if E <= L:\n",
    "            return 0\n",
    "        if np.random.rand() > self.boundary_oversample_p:\n",
    "            return np.random.randint(0, E - L + 1)\n",
    "        trans = np.where(y[1:] != y[:-1])[0] + 1\n",
    "        if trans.size == 0:\n",
    "            return np.random.randint(0, E - L + 1)\n",
    "        t = int(np.random.choice(trans))\n",
    "        start = t - (L // 2)\n",
    "        start = max(0, min(start, E - L))\n",
    "        return int(start)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        d = np.load(p, allow_pickle=True)\n",
    "\n",
    "        x = d[\"x\"].astype(np.float32)   # (E,T)\n",
    "        y = d[\"y\"].astype(np.int64)     # (E,)\n",
    "\n",
    "        if self.exclude_unknown:\n",
    "            keep = (y >= 0)\n",
    "            x = x[keep]\n",
    "            y = y[keep]\n",
    "\n",
    "        if self.do_normalize:\n",
    "            x = normalize_epochs_zscore(x, eps=1e-6, clip=10.0)\n",
    "\n",
    "        E = len(y)\n",
    "\n",
    "        soft = _make_soft_targets_boundary(\n",
    "            y, num_classes=NUM_CLASSES, radius=self.soft_radius, alpha_max=self.soft_alpha_max\n",
    "        )\n",
    "        rem = _compute_runlength_remaining(y)\n",
    "        dur_bucket = _bucketize_remaining(rem, edges=self.dur_edges)\n",
    "\n",
    "        if self.max_hours is not None:\n",
    "            max_L = int((self.max_hours * 3600) / 30)\n",
    "            min_L = int((self.min_hours * 3600) / 30)\n",
    "            L = min(max_L, E)\n",
    "            if E > L:\n",
    "                start = self._pick_block_start_boundary_aware(y, L)\n",
    "                x = x[start:start+L]\n",
    "                y = y[start:start+L]\n",
    "                soft = soft[start:start+L]\n",
    "                dur_bucket = dur_bucket[start:start+L]\n",
    "\n",
    "        if self.mode == \"train\" and self.augmentor is not None:\n",
    "            x = self.augmentor(x, fs=FS)\n",
    "\n",
    "        x_t = torch.from_numpy(x).unsqueeze(1)     # (E,1,T)\n",
    "        y_t = torch.from_numpy(y).long()           # (E,)\n",
    "        soft_t = torch.from_numpy(soft).float()    # (E,C)\n",
    "        dur_t = torch.from_numpy(dur_bucket).long()# (E,)\n",
    "        mask = torch.ones((x_t.shape[0],), dtype=torch.bool)\n",
    "\n",
    "        return x_t, y_t, mask, soft_t, dur_t\n",
    "\n",
    "def collate_pad(batch):\n",
    "    lengths = [b[0].shape[0] for b in batch]\n",
    "    Lmax = max(lengths)\n",
    "    xs, ys, ms, ss, ds = [], [], [], [], []\n",
    "    for x, y, m, s, d in batch:\n",
    "        L = x.shape[0]\n",
    "        padL = Lmax - L\n",
    "        if padL > 0:\n",
    "            x = torch.cat([x, torch.zeros((padL, 1, T), dtype=x.dtype)], dim=0)\n",
    "            y = torch.cat([y, torch.zeros((padL,), dtype=y.dtype)], dim=0)\n",
    "            m = torch.cat([m, torch.zeros((padL,), dtype=torch.bool)], dim=0)\n",
    "            s = torch.cat([s, torch.zeros((padL, NUM_CLASSES), dtype=s.dtype)], dim=0)\n",
    "            d = torch.cat([d, torch.zeros((padL,), dtype=d.dtype)], dim=0)\n",
    "        xs.append(x); ys.append(y); ms.append(m); ss.append(s); ds.append(d)\n",
    "\n",
    "    x = torch.stack(xs, dim=0)\n",
    "    y = torch.stack(ys, dim=0)\n",
    "    m = torch.stack(ms, dim=0)\n",
    "    s = torch.stack(ss, dim=0)\n",
    "    d = torch.stack(ds, dim=0)\n",
    "    return x, y, m, s, d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f948749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SleepSequenceDataset[eval] files=548 max_hours=None normalize=True\n",
      "SleepSequenceDataset[eval] files=548 max_hours=None normalize=True\n",
      "SleepSequenceDataset[eval] files=2536 max_hours=None normalize=True\n",
      "SleepSequenceDataset[eval] files=1856 max_hours=None normalize=True\n",
      "Loaders built: VAL 548 | TEST 548 | SHHS2 2536 | MESA 1856\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 4] Eval loaders (identical)\n",
    "val_seq_ds  = SleepSequenceDataset(df_val,  mode=\"eval\", max_hours=None, augmentor=None, do_normalize=True)\n",
    "test_seq_ds = SleepSequenceDataset(df_test, mode=\"eval\", max_hours=None, augmentor=None, do_normalize=True)\n",
    "ext_seq_ds  = SleepSequenceDataset(df_ext,  mode=\"eval\", max_hours=None, augmentor=None, do_normalize=True)\n",
    "mesa_seq_ds = SleepSequenceDataset(df_mesa, mode=\"eval\", max_hours=None, augmentor=None, do_normalize=True) if df_mesa is not None else None\n",
    "\n",
    "PIN = True\n",
    "val_seq_loader  = DataLoader(val_seq_ds,  batch_size=1, shuffle=False, num_workers=1, pin_memory=PIN, collate_fn=collate_pad)\n",
    "test_seq_loader = DataLoader(test_seq_ds, batch_size=1, shuffle=False, num_workers=1, pin_memory=PIN, collate_fn=collate_pad)\n",
    "ext_seq_loader  = DataLoader(ext_seq_ds,  batch_size=1, shuffle=False, num_workers=1, pin_memory=PIN, collate_fn=collate_pad)\n",
    "mesa_seq_loader = DataLoader(mesa_seq_ds, batch_size=1, shuffle=False, num_workers=1, pin_memory=PIN, collate_fn=collate_pad) if mesa_seq_ds is not None else None\n",
    "\n",
    "print(\"Loaders built:\",\n",
    "      \"VAL\", len(val_seq_loader),\n",
    "      \"| TEST\", len(test_seq_loader),\n",
    "      \"| SHHS2\", len(ext_seq_loader),\n",
    "      \"| MESA\", (len(mesa_seq_loader) if mesa_seq_loader is not None else None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a430b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params (M): 22.905512\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 5] Model (identical) + loss helpers needed for eval\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.drop_prob = float(drop_prob)\n",
    "    def forward(self, x):\n",
    "        if (not self.training) or self.drop_prob == 0.0:\n",
    "            return x\n",
    "        keep = 1.0 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        rand = keep + torch.rand(shape, device=x.device)\n",
    "        mask = torch.floor(rand)\n",
    "        return x / keep * mask\n",
    "\n",
    "class ResConv1D(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k, s=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(c_in, c_out, k, stride=s, padding=k//2),\n",
    "            nn.BatchNorm1d(c_out),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(c_out, c_out, k, padding=k//2),\n",
    "            nn.BatchNorm1d(c_out),\n",
    "        )\n",
    "        self.skip = nn.Conv1d(c_in, c_out, 1, stride=s) if (c_in != c_out or s != 1) else nn.Identity()\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x) + self.skip(x))\n",
    "\n",
    "class EpochEncoder(nn.Module):\n",
    "    def __init__(self, d_model=384):\n",
    "        super().__init__()\n",
    "        self.branch_short = ResConv1D(1, 128, k=7,  s=4)\n",
    "        self.branch_mid   = ResConv1D(1, 128, k=15, s=4)\n",
    "        self.branch_long  = ResConv1D(1, 128, k=31, s=4)\n",
    "\n",
    "        self.freq_proj = nn.Sequential(\n",
    "            nn.Linear(1876, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Linear(128*3 + 256, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, _, T_ = x.shape\n",
    "        x = x.view(B*L, 1, T_)\n",
    "\n",
    "        zs = self.branch_short(x).mean(-1)\n",
    "        zm = self.branch_mid(x).mean(-1)\n",
    "        zl = self.branch_long(x).mean(-1)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            xf32 = x.squeeze(1).float()\n",
    "            Xf = torch.fft.rfft(xf32, dim=-1)\n",
    "            mag = torch.abs(Xf)\n",
    "            mag = mag[:, :1876]\n",
    "            mag = torch.log1p(mag)\n",
    "            mag = mag / (mag.mean(dim=1, keepdim=True) + 1e-6)\n",
    "\n",
    "        zf = self.freq_proj(mag)\n",
    "        z = torch.cat([zs, zm, zl, zf.to(zs.dtype)], dim=-1)\n",
    "        z = self.fuse(z)\n",
    "        return z.view(B, L, -1)\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1 = x[..., ::2]\n",
    "    x2 = x[..., 1::2]\n",
    "    return torch.stack((-x2, x1), dim=-1).flatten(-2)\n",
    "\n",
    "class RoPE(nn.Module):\n",
    "    def __init__(self, head_dim, base=10000):\n",
    "        super().__init__()\n",
    "        assert head_dim % 2 == 0\n",
    "        self.head_dim = head_dim\n",
    "        self.base = base\n",
    "    def forward(self, x):\n",
    "        B, L, H, Dh = x.shape\n",
    "        half = Dh // 2\n",
    "        freqs = 1.0 / (self.base ** (torch.arange(half, device=x.device) / half))\n",
    "        t = torch.arange(L, device=x.device)\n",
    "        angles = torch.einsum(\"l,d->ld\", t, freqs)\n",
    "        cos = torch.cos(angles)[None, :, None, :]\n",
    "        sin = torch.sin(angles)[None, :, None, :]\n",
    "        cos = cos.repeat_interleave(2, dim=-1)\n",
    "        sin = sin.repeat_interleave(2, dim=-1)\n",
    "        return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "def _windows(L, w):\n",
    "    out = []\n",
    "    s = 0\n",
    "    while s < L:\n",
    "        e = min(L, s + w)\n",
    "        out.append((s, e))\n",
    "        s = e\n",
    "    return out\n",
    "\n",
    "class MultiHeadSelfAttentionRoPE_LocalGlobal(nn.Module):\n",
    "    def __init__(self, d_model=384, n_heads=8, dropout=0.1, window_size=64):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.window_size = int(window_size)\n",
    "\n",
    "        self.qkv = nn.Linear(d_model, 3*d_model)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.rope = RoPE(self.d_head)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None, global_attn=False):\n",
    "        B, L, D = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        q = q.view(B, L, self.n_heads, self.d_head)\n",
    "        k = k.view(B, L, self.n_heads, self.d_head)\n",
    "        v = v.view(B, L, self.n_heads, self.d_head)\n",
    "\n",
    "        q = self.rope(q)\n",
    "        k = self.rope(k)\n",
    "\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        if global_attn or self.window_size >= L:\n",
    "            scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "            scores = scores.float()\n",
    "            if key_padding_mask is not None:\n",
    "                scores = scores.masked_fill(~key_padding_mask[:, None, None, :], -1e9)\n",
    "            attn = torch.softmax(scores, dim=-1)\n",
    "            attn = self.drop(attn).to(v.dtype)\n",
    "            out = attn @ v\n",
    "            out = out.transpose(1, 2).contiguous().view(B, L, D)\n",
    "            return self.proj(out)\n",
    "\n",
    "        w = self.window_size\n",
    "        out = torch.zeros((B, self.n_heads, L, self.d_head), device=x.device, dtype=v.dtype)\n",
    "        for (s, e) in _windows(L, w):\n",
    "            qs = q[:, :, s:e, :]\n",
    "            ks = k[:, :, s:e, :]\n",
    "            vs = v[:, :, s:e, :]\n",
    "\n",
    "            scores = (qs @ ks.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "            scores = scores.float()\n",
    "            if key_padding_mask is not None:\n",
    "                m = key_padding_mask[:, s:e]\n",
    "                scores = scores.masked_fill(~m[:, None, None, :], -1e9)\n",
    "\n",
    "            attn = torch.softmax(scores, dim=-1)\n",
    "            attn = self.drop(attn).to(vs.dtype)\n",
    "            out[:, :, s:e, :] = attn @ vs\n",
    "\n",
    "        out = out.transpose(1, 2).contiguous().view(B, L, D)\n",
    "        return self.proj(out)\n",
    "\n",
    "class TransformerBlockLG(nn.Module):\n",
    "    def __init__(self, d_model=384, n_heads=8, drop=0.1, drop_path=0.1, window_size=64):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.attn = MultiHeadSelfAttentionRoPE_LocalGlobal(d_model, n_heads, drop, window_size=window_size)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, 4*d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(4*d_model, d_model),\n",
    "        )\n",
    "        self.dp = DropPath(drop_path)\n",
    "\n",
    "    def forward(self, x, mask, global_attn=False):\n",
    "        x = x + self.dp(self.attn(self.ln1(x), key_padding_mask=mask, global_attn=global_attn))\n",
    "        x = x + self.dp(self.mlp(self.ln2(x)))\n",
    "        return x\n",
    "\n",
    "class HierSleepTransformerV5_1(nn.Module):\n",
    "    def __init__(self, num_classes=5, d_model=384, depth=12, n_heads=8,\n",
    "                 dur_bins=8, window_size=64, global_every=3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.dur_bins = dur_bins\n",
    "        self.depth = int(depth)\n",
    "        self.global_every = int(global_every)\n",
    "\n",
    "        self.encoder = EpochEncoder(d_model)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlockLG(\n",
    "                d_model=d_model,\n",
    "                n_heads=n_heads,\n",
    "                drop=0.1,\n",
    "                drop_path=0.1*(i+1)/depth,\n",
    "                window_size=window_size\n",
    "            )\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "        self.head = nn.Linear(d_model, num_classes)\n",
    "\n",
    "        self.aux_n1 = nn.Linear(d_model, 2)\n",
    "        self.aux_dur = nn.Linear(d_model, dur_bins)\n",
    "        self.trans_logits = nn.Parameter(torch.zeros(num_classes, num_classes))\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        z = self.encoder(x)\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            use_global = (self.global_every > 0) and ((i % self.global_every) == 0)\n",
    "            z = blk(z, mask, global_attn=use_global)\n",
    "        main_logits = self.head(z)\n",
    "        aux_logits  = self.aux_n1(z)\n",
    "        dur_logits  = self.aux_dur(z)\n",
    "        return main_logits, aux_logits, dur_logits\n",
    "\n",
    "# dur bins\n",
    "DUR_EDGES = (2,5,10,20,40,80,160)\n",
    "DUR_BINS = len(DUR_EDGES) + 1\n",
    "\n",
    "model = HierSleepTransformerV5_1(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    d_model=384,\n",
    "    depth=12,\n",
    "    n_heads=8,\n",
    "    dur_bins=DUR_BINS,\n",
    "    window_size=64,\n",
    "    global_every=3\n",
    ").to(device)\n",
    "\n",
    "print(\"Model params (M):\", sum(p.numel() for p in model.parameters()) / 1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b721bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# %% [CELL 6] Loss switches + helpers (identical defaults)\n",
    "USE_LA_CE = True\n",
    "LA_TAU = 1.0\n",
    "USE_HARD_NEG_N1 = True\n",
    "HARD_NEG_MULT = 2.0\n",
    "\n",
    "USE_SOFT_BOUNDARY_LOSS = True\n",
    "SOFT_BOUNDARY_WEIGHT = 0.25\n",
    "\n",
    "USE_COST_MATRIX = True\n",
    "COST_WEIGHT = 0.20\n",
    "\n",
    "USE_AUX_N1 = True\n",
    "AUX_N1_WEIGHT = 0.30\n",
    "\n",
    "USE_AUX_DUR = True\n",
    "AUX_DUR_WEIGHT = 0.15\n",
    "AUX_DUR_N1_MULT = 1.50\n",
    "\n",
    "USE_TRANS_LOSS = True\n",
    "TRANS_LOSS_WEIGHT = 0.10\n",
    "\n",
    "USE_LEARNED_SMOOTHING = True\n",
    "USE_VITERBI = False  # keep same as your eval default\n",
    "\n",
    "# class weights from your train set (needed for LA-CE prior)\n",
    "def class_counts_train(df):\n",
    "    c = Counter()\n",
    "    for p in tqdm(df[\"npz_path\"].tolist(), desc=\"Counting train labels\", leave=False):\n",
    "        d = np.load(p, allow_pickle=True)\n",
    "        y = d[\"y\"].astype(np.int64)\n",
    "        y = y[y >= 0]\n",
    "        c.update(y.tolist())\n",
    "    counts = np.array([c.get(i, 0) for i in range(NUM_CLASSES)], dtype=np.float64)\n",
    "    return counts\n",
    "\n",
    "counts = class_counts_train(df_train)\n",
    "\n",
    "class LogitAdjustedCE(nn.Module):\n",
    "    def __init__(self, class_freq, tau=1.0):\n",
    "        super().__init__()\n",
    "        freq = torch.tensor(class_freq, dtype=torch.float32)\n",
    "        self.register_buffer(\"log_prior\", torch.log(freq / freq.sum()))\n",
    "        self.tau = float(tau)\n",
    "    def forward(self, logits, targets, reduction=\"none\"):\n",
    "        logits = logits + self.tau * self.log_prior\n",
    "        return F.cross_entropy(logits, targets, reduction=reduction)\n",
    "\n",
    "def label_smoothing_nll(logits, targets, smooth_per_class):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    nll = -logp.gather(dim=-1, index=targets.view(-1,1)).squeeze(1)\n",
    "    smooth = -logp.mean(dim=-1)\n",
    "    s = smooth_per_class[targets]\n",
    "    return (1 - s) * nll + s * smooth\n",
    "\n",
    "smooth_vec = torch.tensor([0.02, 0.00, 0.05, 0.05, 0.02], dtype=torch.float32).to(device)\n",
    "la_ce = LogitAdjustedCE(class_freq=counts, tau=LA_TAU).to(device)\n",
    "\n",
    "def soft_target_ce(logits, soft_targets):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    return -(soft_targets * logp).sum(dim=-1)\n",
    "\n",
    "def build_cost_matrix(device):\n",
    "    C = NUM_CLASSES\n",
    "    cost = torch.zeros((C, C), dtype=torch.float32, device=device)\n",
    "    cost += 0.05\n",
    "    cost.fill_diagonal_(0.0)\n",
    "    cost[1, 0] = 1.00\n",
    "    cost[1, 2] = 1.00\n",
    "    cost[0, 1] = 0.60\n",
    "    cost[2, 1] = 0.60\n",
    "    cost[2, 3] = 0.20\n",
    "    cost[3, 2] = 0.20\n",
    "    cost[0, 4] = 0.15\n",
    "    cost[4, 0] = 0.15\n",
    "    return cost\n",
    "\n",
    "COST_MAT = build_cost_matrix(device)\n",
    "\n",
    "def compute_transition_loss(model, y, mask):\n",
    "    B, L = y.shape\n",
    "    y_prev = y[:, :-1]\n",
    "    y_next = y[:, 1:]\n",
    "    m_pair = mask[:, :-1] & mask[:, 1:]\n",
    "    if m_pair.sum().item() == 0:\n",
    "        return torch.zeros((), device=y.device)\n",
    "    y_prev_v = y_prev[m_pair]\n",
    "    y_next_v = y_next[m_pair]\n",
    "    trans_logits = model.trans_logits\n",
    "    logits_pair = trans_logits[y_prev_v]\n",
    "    return F.cross_entropy(logits_pair, y_next_v)\n",
    "\n",
    "def masked_loss_v5(model, main_logits, aux_logits, dur_logits, y, mask, soft_targets, dur_bucket):\n",
    "    B, L, C = main_logits.shape\n",
    "    logits2 = main_logits.view(B*L, C)\n",
    "    y2 = y.view(B*L)\n",
    "    m2 = mask.view(B*L)\n",
    "\n",
    "    logits_valid = logits2[m2]\n",
    "    y_valid = y2[m2]\n",
    "\n",
    "    if USE_LA_CE:\n",
    "        adj_logits = logits_valid + la_ce.tau * la_ce.log_prior\n",
    "        loss_main_vec = label_smoothing_nll(adj_logits, y_valid, smooth_vec)\n",
    "    else:\n",
    "        loss_main_vec = label_smoothing_nll(logits_valid, y_valid, smooth_vec)\n",
    "\n",
    "    if USE_HARD_NEG_N1:\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(logits_valid, dim=-1)\n",
    "            hard = (y_valid == 1) & ((pred == 0) | (pred == 2))\n",
    "        loss_main_vec = loss_main_vec * torch.where(\n",
    "            hard,\n",
    "            torch.tensor(HARD_NEG_MULT, device=logits_valid.device),\n",
    "            torch.tensor(1.0, device=logits_valid.device)\n",
    "        )\n",
    "\n",
    "    loss = loss_main_vec.mean()\n",
    "\n",
    "    if USE_SOFT_BOUNDARY_LOSS:\n",
    "        soft2 = soft_targets.view(B*L, C)[m2]\n",
    "        if USE_LA_CE:\n",
    "            adj_logits_soft = logits_valid + la_ce.tau * la_ce.log_prior\n",
    "            loss_soft_vec = soft_target_ce(adj_logits_soft, soft2)\n",
    "        else:\n",
    "            loss_soft_vec = soft_target_ce(logits_valid, soft2)\n",
    "        loss = loss + SOFT_BOUNDARY_WEIGHT * loss_soft_vec.mean()\n",
    "\n",
    "    if USE_COST_MATRIX:\n",
    "        probs = torch.softmax(logits_valid.float(), dim=-1)\n",
    "        cost_row = COST_MAT[y_valid]\n",
    "        expected_cost = (probs * cost_row).sum(dim=-1)\n",
    "        loss = loss + COST_WEIGHT * expected_cost.mean()\n",
    "\n",
    "    if USE_AUX_N1:\n",
    "        aux2 = aux_logits.view(B*L, 2)[m2]\n",
    "        y_aux = (y_valid == 1).long()\n",
    "        loss_aux = F.cross_entropy(aux2, y_aux)\n",
    "        loss = loss + AUX_N1_WEIGHT * loss_aux\n",
    "\n",
    "    if USE_AUX_DUR:\n",
    "        dur2 = dur_logits.view(B*L, DUR_BINS)[m2]\n",
    "        dur_t = dur_bucket.view(B*L)[m2]\n",
    "        w = torch.ones_like(dur_t, dtype=torch.float32, device=dur2.device)\n",
    "        w = w * torch.where(y_valid == 1, torch.tensor(AUX_DUR_N1_MULT, device=dur2.device), torch.tensor(1.0, device=dur2.device))\n",
    "        loss_dur = F.cross_entropy(dur2, dur_t, reduction=\"none\")\n",
    "        loss_dur = (loss_dur * w).mean()\n",
    "        loss = loss + AUX_DUR_WEIGHT * loss_dur\n",
    "\n",
    "    if USE_TRANS_LOSS:\n",
    "        loss_trans = compute_transition_loss(model, y, mask)\n",
    "        loss = loss + TRANS_LOSS_WEIGHT * loss_trans\n",
    "\n",
    "    return loss\n",
    "\n",
    "def apply_learned_smoothing_probs(probs, model):\n",
    "    Tm = torch.softmax(model.trans_logits, dim=1)\n",
    "    return probs @ Tm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9f29fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# %% [CELL 6] Loss switches + helpers (identical defaults)\n",
    "USE_LA_CE = True\n",
    "LA_TAU = 1.0\n",
    "USE_HARD_NEG_N1 = True\n",
    "HARD_NEG_MULT = 2.0\n",
    "\n",
    "USE_SOFT_BOUNDARY_LOSS = True\n",
    "SOFT_BOUNDARY_WEIGHT = 0.25\n",
    "\n",
    "USE_COST_MATRIX = True\n",
    "COST_WEIGHT = 0.20\n",
    "\n",
    "USE_AUX_N1 = True\n",
    "AUX_N1_WEIGHT = 0.30\n",
    "\n",
    "USE_AUX_DUR = True\n",
    "AUX_DUR_WEIGHT = 0.15\n",
    "AUX_DUR_N1_MULT = 1.50\n",
    "\n",
    "USE_TRANS_LOSS = True\n",
    "TRANS_LOSS_WEIGHT = 0.10\n",
    "\n",
    "USE_LEARNED_SMOOTHING = True\n",
    "USE_VITERBI = False  # keep same as your eval default\n",
    "\n",
    "# class weights from your train set (needed for LA-CE prior)\n",
    "def class_counts_train(df):\n",
    "    c = Counter()\n",
    "    for p in tqdm(df[\"npz_path\"].tolist(), desc=\"Counting train labels\", leave=False):\n",
    "        d = np.load(p, allow_pickle=True)\n",
    "        y = d[\"y\"].astype(np.int64)\n",
    "        y = y[y >= 0]\n",
    "        c.update(y.tolist())\n",
    "    counts = np.array([c.get(i, 0) for i in range(NUM_CLASSES)], dtype=np.float64)\n",
    "    return counts\n",
    "\n",
    "counts = class_counts_train(df_train)\n",
    "\n",
    "class LogitAdjustedCE(nn.Module):\n",
    "    def __init__(self, class_freq, tau=1.0):\n",
    "        super().__init__()\n",
    "        freq = torch.tensor(class_freq, dtype=torch.float32)\n",
    "        self.register_buffer(\"log_prior\", torch.log(freq / freq.sum()))\n",
    "        self.tau = float(tau)\n",
    "    def forward(self, logits, targets, reduction=\"none\"):\n",
    "        logits = logits + self.tau * self.log_prior\n",
    "        return F.cross_entropy(logits, targets, reduction=reduction)\n",
    "\n",
    "def label_smoothing_nll(logits, targets, smooth_per_class):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    nll = -logp.gather(dim=-1, index=targets.view(-1,1)).squeeze(1)\n",
    "    smooth = -logp.mean(dim=-1)\n",
    "    s = smooth_per_class[targets]\n",
    "    return (1 - s) * nll + s * smooth\n",
    "\n",
    "smooth_vec = torch.tensor([0.02, 0.00, 0.05, 0.05, 0.02], dtype=torch.float32).to(device)\n",
    "la_ce = LogitAdjustedCE(class_freq=counts, tau=LA_TAU).to(device)\n",
    "\n",
    "def soft_target_ce(logits, soft_targets):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    return -(soft_targets * logp).sum(dim=-1)\n",
    "\n",
    "def build_cost_matrix(device):\n",
    "    C = NUM_CLASSES\n",
    "    cost = torch.zeros((C, C), dtype=torch.float32, device=device)\n",
    "    cost += 0.05\n",
    "    cost.fill_diagonal_(0.0)\n",
    "    cost[1, 0] = 1.00\n",
    "    cost[1, 2] = 1.00\n",
    "    cost[0, 1] = 0.60\n",
    "    cost[2, 1] = 0.60\n",
    "    cost[2, 3] = 0.20\n",
    "    cost[3, 2] = 0.20\n",
    "    cost[0, 4] = 0.15\n",
    "    cost[4, 0] = 0.15\n",
    "    return cost\n",
    "\n",
    "COST_MAT = build_cost_matrix(device)\n",
    "\n",
    "def compute_transition_loss(model, y, mask):\n",
    "    B, L = y.shape\n",
    "    y_prev = y[:, :-1]\n",
    "    y_next = y[:, 1:]\n",
    "    m_pair = mask[:, :-1] & mask[:, 1:]\n",
    "    if m_pair.sum().item() == 0:\n",
    "        return torch.zeros((), device=y.device)\n",
    "    y_prev_v = y_prev[m_pair]\n",
    "    y_next_v = y_next[m_pair]\n",
    "    trans_logits = model.trans_logits\n",
    "    logits_pair = trans_logits[y_prev_v]\n",
    "    return F.cross_entropy(logits_pair, y_next_v)\n",
    "\n",
    "def masked_loss_v5(model, main_logits, aux_logits, dur_logits, y, mask, soft_targets, dur_bucket):\n",
    "    B, L, C = main_logits.shape\n",
    "    logits2 = main_logits.view(B*L, C)\n",
    "    y2 = y.view(B*L)\n",
    "    m2 = mask.view(B*L)\n",
    "\n",
    "    logits_valid = logits2[m2]\n",
    "    y_valid = y2[m2]\n",
    "\n",
    "    if USE_LA_CE:\n",
    "        adj_logits = logits_valid + la_ce.tau * la_ce.log_prior\n",
    "        loss_main_vec = label_smoothing_nll(adj_logits, y_valid, smooth_vec)\n",
    "    else:\n",
    "        loss_main_vec = label_smoothing_nll(logits_valid, y_valid, smooth_vec)\n",
    "\n",
    "    if USE_HARD_NEG_N1:\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(logits_valid, dim=-1)\n",
    "            hard = (y_valid == 1) & ((pred == 0) | (pred == 2))\n",
    "        loss_main_vec = loss_main_vec * torch.where(\n",
    "            hard,\n",
    "            torch.tensor(HARD_NEG_MULT, device=logits_valid.device),\n",
    "            torch.tensor(1.0, device=logits_valid.device)\n",
    "        )\n",
    "\n",
    "    loss = loss_main_vec.mean()\n",
    "\n",
    "    if USE_SOFT_BOUNDARY_LOSS:\n",
    "        soft2 = soft_targets.view(B*L, C)[m2]\n",
    "        if USE_LA_CE:\n",
    "            adj_logits_soft = logits_valid + la_ce.tau * la_ce.log_prior\n",
    "            loss_soft_vec = soft_target_ce(adj_logits_soft, soft2)\n",
    "        else:\n",
    "            loss_soft_vec = soft_target_ce(logits_valid, soft2)\n",
    "        loss = loss + SOFT_BOUNDARY_WEIGHT * loss_soft_vec.mean()\n",
    "\n",
    "    if USE_COST_MATRIX:\n",
    "        probs = torch.softmax(logits_valid.float(), dim=-1)\n",
    "        cost_row = COST_MAT[y_valid]\n",
    "        expected_cost = (probs * cost_row).sum(dim=-1)\n",
    "        loss = loss + COST_WEIGHT * expected_cost.mean()\n",
    "\n",
    "    if USE_AUX_N1:\n",
    "        aux2 = aux_logits.view(B*L, 2)[m2]\n",
    "        y_aux = (y_valid == 1).long()\n",
    "        loss_aux = F.cross_entropy(aux2, y_aux)\n",
    "        loss = loss + AUX_N1_WEIGHT * loss_aux\n",
    "\n",
    "    if USE_AUX_DUR:\n",
    "        dur2 = dur_logits.view(B*L, DUR_BINS)[m2]\n",
    "        dur_t = dur_bucket.view(B*L)[m2]\n",
    "        w = torch.ones_like(dur_t, dtype=torch.float32, device=dur2.device)\n",
    "        w = w * torch.where(y_valid == 1, torch.tensor(AUX_DUR_N1_MULT, device=dur2.device), torch.tensor(1.0, device=dur2.device))\n",
    "        loss_dur = F.cross_entropy(dur2, dur_t, reduction=\"none\")\n",
    "        loss_dur = (loss_dur * w).mean()\n",
    "        loss = loss + AUX_DUR_WEIGHT * loss_dur\n",
    "\n",
    "    if USE_TRANS_LOSS:\n",
    "        loss_trans = compute_transition_loss(model, y, mask)\n",
    "        loss = loss + TRANS_LOSS_WEIGHT * loss_trans\n",
    "\n",
    "    return loss\n",
    "\n",
    "def apply_learned_smoothing_probs(probs, model):\n",
    "    Tm = torch.softmax(model.trans_logits, dim=1)\n",
    "    return probs @ Tm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "984756a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/checkpoints_hier_rope_seq_v5_1/BEST_VAL_macroF1.pt\n",
      "Loaded model_state. missing: 0 | unexpected: 0\n",
      "Applied EMA shadow tensors: 189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HierSleepTransformerV5_1(\n",
       "  (encoder): EpochEncoder(\n",
       "    (branch_short): ResConv1D(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv1d(1, 128, kernel_size=(7,), stride=(4,), padding=(3,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate=none)\n",
       "        (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Conv1d(1, 128, kernel_size=(1,), stride=(4,))\n",
       "      (act): GELU(approximate=none)\n",
       "    )\n",
       "    (branch_mid): ResConv1D(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv1d(1, 128, kernel_size=(15,), stride=(4,), padding=(7,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate=none)\n",
       "        (3): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Conv1d(1, 128, kernel_size=(1,), stride=(4,))\n",
       "      (act): GELU(approximate=none)\n",
       "    )\n",
       "    (branch_long): ResConv1D(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv1d(1, 128, kernel_size=(31,), stride=(4,), padding=(15,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate=none)\n",
       "        (3): Conv1d(128, 128, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Conv1d(1, 128, kernel_size=(1,), stride=(4,))\n",
       "      (act): GELU(approximate=none)\n",
       "    )\n",
       "    (freq_proj): Sequential(\n",
       "      (0): Linear(in_features=1876, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate=none)\n",
       "    )\n",
       "    (fuse): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate=none)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (1): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (2): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (3): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (4): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (5): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (6): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (7): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (8): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (9): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (10): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "    (11): TransformerBlockLG(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadSelfAttentionRoPE_LocalGlobal(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (rope): RoPE()\n",
       "      )\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate=none)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "      )\n",
       "      (dp): DropPath()\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=384, out_features=5, bias=True)\n",
       "  (aux_n1): Linear(in_features=384, out_features=2, bias=True)\n",
       "  (aux_dur): Linear(in_features=384, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [CELL 7] Load checkpoint + apply EMA shadow (identical)\n",
    "CKPT_DIR = ROOT / \"checkpoints_hier_rope_seq_v5_1\"\n",
    "BEST_CKPT = CKPT_DIR / \"BEST_VAL_macroF1.pt\"   # change if needed\n",
    "assert BEST_CKPT.exists(), f\"Missing ckpt: {BEST_CKPT}\"\n",
    "print(\"Loading:\", BEST_CKPT)\n",
    "\n",
    "ckpt = torch.load(BEST_CKPT, map_location=\"cpu\")\n",
    "sd = ckpt[\"model_state\"]\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"Loaded model_state. missing:\", len(missing), \"| unexpected:\", len(unexpected))\n",
    "\n",
    "use_ema = bool(ckpt.get(\"use_ema\", False))\n",
    "ema_shadow = ckpt.get(\"ema_shadow\", None)\n",
    "\n",
    "if use_ema and isinstance(ema_shadow, dict) and len(ema_shadow) > 0:\n",
    "    with torch.no_grad():\n",
    "        curr = model.state_dict()\n",
    "        applied = 0\n",
    "        for k, v in ema_shadow.items():\n",
    "            if k in curr:\n",
    "                curr[k].copy_(v.to(curr[k].device).to(curr[k].dtype))\n",
    "                applied += 1\n",
    "        model.load_state_dict(curr, strict=False)\n",
    "    print(\"Applied EMA shadow tensors:\", applied)\n",
    "else:\n",
    "    print(\"EMA shadow not applied (missing/disabled).\")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e0dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [CELL 8] Eval (identical behavior) + return raw arrays for saving\n",
    "def _ece_from_probs(y_true, probs, n_bins=15):\n",
    "    conf = probs.max(axis=1)\n",
    "    pred = probs.argmax(axis=1)\n",
    "    acc = (pred == y_true).astype(np.float32)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        m = (conf >= lo) & (conf < hi)\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        bin_acc = acc[m].mean()\n",
    "        bin_conf = conf[m].mean()\n",
    "        ece += (m.mean()) * abs(bin_acc - bin_conf)\n",
    "    return float(ece)\n",
    "\n",
    "def _auroc_auprc_multiclass(y_true, probs, num_classes=5):\n",
    "    Y = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "    aurocs, auprcs = [], []\n",
    "    for c in range(num_classes):\n",
    "        if Y[:, c].sum() == 0:\n",
    "            continue\n",
    "        try:\n",
    "            aurocs.append(roc_auc_score(Y[:, c], probs[:, c]))\n",
    "            auprcs.append(average_precision_score(Y[:, c], probs[:, c]))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if len(aurocs) == 0:\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "    return float(np.mean(aurocs)), float(np.mean(auprcs))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_sequence_collect(model, loader, desc=\"Eval\"):\n",
    "    model.eval()\n",
    "\n",
    "    all_true, all_pred, all_probs = [], [], []\n",
    "    total_loss = 0.0\n",
    "    total_n = 0\n",
    "    bad_batches = 0\n",
    "\n",
    "    for bidx, (xb, yb, mb, sb, db) in enumerate(tqdm(loader, desc=desc, leave=False)):\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        mb = mb.to(device, non_blocking=True)\n",
    "        sb = sb.to(device, non_blocking=True)\n",
    "        db = db.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "            main_logits, aux_logits, dur_logits = model(xb, mb)\n",
    "            loss = masked_loss_v5(model, main_logits, aux_logits, dur_logits, yb, mb, sb, db)\n",
    "\n",
    "        if (not torch.isfinite(main_logits).all()) or (not torch.isfinite(loss)):\n",
    "            bad_batches += 1\n",
    "            continue\n",
    "\n",
    "        probs = torch.softmax(main_logits.float(), dim=-1)\n",
    "        if USE_LEARNED_SMOOTHING:\n",
    "            probs = apply_learned_smoothing_probs(probs, model)\n",
    "\n",
    "        if not torch.isfinite(probs).all():\n",
    "            bad_batches += 1\n",
    "            continue\n",
    "\n",
    "        pred = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        yv = yb[mb].detach().cpu().numpy()\n",
    "        pv = pred[mb].detach().cpu().numpy()\n",
    "        pr = probs[mb].detach().cpu().numpy()\n",
    "\n",
    "        if yv.size == 0:\n",
    "            continue\n",
    "\n",
    "        all_true.append(yv)\n",
    "        all_pred.append(pv)\n",
    "        all_probs.append(pr)\n",
    "\n",
    "        n = int(mb.sum().item())\n",
    "        total_loss += float(loss.item()) * n\n",
    "        total_n += n\n",
    "\n",
    "    if len(all_true) == 0:\n",
    "        metrics = {\n",
    "            \"loss\": float(\"nan\"), \"acc\": float(\"nan\"), \"macro_f1\": float(\"nan\"), \"kappa\": float(\"nan\"),\n",
    "            \"AUROC\": float(\"nan\"), \"AUPRC\": float(\"nan\"), \"meanConf\": float(\"nan\"), \"ECE\": float(\"nan\"),\n",
    "            \"f1_per_class\": {LABELS[i]: float(\"nan\") for i in range(NUM_CLASSES)},\n",
    "            \"cm\": np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=np.int64),\n",
    "            \"bad_batches\": int(bad_batches),\n",
    "        }\n",
    "        return metrics, None\n",
    "\n",
    "    y_true = np.concatenate(all_true)\n",
    "    y_pred = np.concatenate(all_pred)\n",
    "    probs_all = np.concatenate(all_probs)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
    "\n",
    "    auroc, auprc = _auroc_auprc_multiclass(y_true, probs_all, num_classes=NUM_CLASSES)\n",
    "    mean_conf = float(probs_all.max(axis=1).mean())\n",
    "    ece = _ece_from_probs(y_true, probs_all, n_bins=15)\n",
    "\n",
    "    f1_per = {LABELS[i]: float(f1_score((y_true==i).astype(int), (y_pred==i).astype(int)))\n",
    "              for i in range(NUM_CLASSES)}\n",
    "\n",
    "    metrics = {\n",
    "        \"loss\": total_loss / max(total_n, 1),\n",
    "        \"acc\": float(acc),\n",
    "        \"macro_f1\": float(mf1),\n",
    "        \"kappa\": float(kappa),\n",
    "        \"AUROC\": auroc,\n",
    "        \"AUPRC\": auprc,\n",
    "        \"meanConf\": mean_conf,\n",
    "        \"ECE\": ece,\n",
    "        \"f1_per_class\": f1_per,\n",
    "        \"cm\": cm,\n",
    "        \"bad_batches\": int(bad_batches),\n",
    "    }\n",
    "\n",
    "    raw = {\"y_true\": y_true, \"y_pred\": y_pred, \"probs\": probs_all}\n",
    "    return metrics, raw\n",
    "\n",
    "def print_metrics(tag, m):\n",
    "    print(f\"\\n===== {tag} =====\")\n",
    "    for k in [\"loss\",\"acc\",\"macro_f1\",\"kappa\",\"AUROC\",\"AUPRC\",\"meanConf\",\"ECE\"]:\n",
    "        if k in m:\n",
    "            print(f\"{k:9s}: {m[k]:.4f}\" if isinstance(m[k], (float,int)) else f\"{k:9s}: {m[k]}\")\n",
    "    if \"bad_batches\" in m:\n",
    "        print(\"bad_batches:\", m[\"bad_batches\"])\n",
    "    if \"f1_per_class\" in m:\n",
    "        print(\"F1/class :\", m[\"f1_per_class\"])\n",
    "    if \"cm\" in m:\n",
    "        labs = [LABELS[i] for i in range(NUM_CLASSES)]\n",
    "        print(\"Confusion Matrix labels:\", labs)\n",
    "        print(m[\"cm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e7d7c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== VAL =====\n",
      "loss     : 0.8562\n",
      "acc      : 0.8568\n",
      "macro_f1 : 0.8019\n",
      "kappa    : 0.8025\n",
      "AUROC    : 0.9702\n",
      "AUPRC    : 0.8488\n",
      "meanConf : 0.6985\n",
      "ECE      : 0.1583\n",
      "bad_batches: 0\n",
      "F1/class : {'W': 0.9147962818323049, 'N1': 0.5222609682912983, 'N2': 0.8653339068314851, 'N3': 0.8254334653621173, 'REM': 0.8819111537232341}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[106582   5961   4623    503   1969]\n",
      " [  2237  12880   3175     10   1733]\n",
      " [  3628   8370 185088  16458   9607]\n",
      " [   228     22   9001  62936    195]\n",
      " [   705   2056   2746    203  71747]]\n",
      "\n",
      "===== SHHS1 TEST =====\n",
      "loss     : 0.8165\n",
      "acc      : 0.8655\n",
      "macro_f1 : 0.8108\n",
      "kappa    : 0.8144\n",
      "AUROC    : 0.9737\n",
      "AUPRC    : 0.8622\n",
      "meanConf : 0.6987\n",
      "ECE      : 0.1668\n",
      "bad_batches: 0\n",
      "F1/class : {'W': 0.9216682597977562, 'N1': 0.536456381428274, 'N2': 0.8737501224798317, 'N3': 0.8319843540426431, 'REM': 0.8902020233270428}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[109920   5925   3963    418   2187]\n",
      " [  1898  12883   3316     12   1736]\n",
      " [  3512   7534 187263  16348   8882]\n",
      " [   117     10   8321  62960    167]\n",
      " [   664   1833   2240     36  71935]]\n",
      "\n",
      "===== SHHS2 EXT =====\n",
      "loss     : 0.7900\n",
      "acc      : 0.8695\n",
      "macro_f1 : 0.8029\n",
      "kappa    : 0.8194\n",
      "AUROC    : 0.9739\n",
      "AUPRC    : 0.8616\n",
      "meanConf : 0.6927\n",
      "ECE      : 0.1767\n",
      "bad_batches: 0\n",
      "F1/class : {'W': 0.9261886289355289, 'N1': 0.5053704868729958, 'N2': 0.8740103412080054, 'N3': 0.80937367749758, 'REM': 0.8993172605597928}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[830869  45451  38238   7144  15315]\n",
      " [  7303  65871  22876    154   9414]\n",
      " [ 15041  32484 943804  93273  24486]\n",
      " [   362     29  28164 276357    319]\n",
      " [  3576  11231  17539    732 368953]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== MESA EXT =====\n",
      "loss     : 1.4269\n",
      "acc      : 0.7713\n",
      "macro_f1 : 0.6292\n",
      "kappa    : 0.6698\n",
      "AUROC    : 0.9210\n",
      "AUPRC    : 0.7162\n",
      "meanConf : 0.6540\n",
      "ECE      : 0.1173\n",
      "bad_batches: 0\n",
      "F1/class : {'W': 0.8768155814387883, 'N1': 0.4071434383372159, 'N2': 0.7838374053621394, 'N3': 0.2764576584914391, 'REM': 0.801973383872619}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[692384  25860  69702   2217  39800]\n",
      " [ 23939  67551  75639     50  20011]\n",
      " [ 24904  47000 689414   5824  30756]\n",
      " [  1618    125 114166  23897    971]\n",
      " [  6507   4103  12255    115 231889]]\n",
      "\n",
      "Saved:\n",
      " - /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/eval_outputs_fresh_notebook/EVAL_SHHS2_MESA_bundle.json\n",
      " - /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/eval_outputs_fresh_notebook/EVAL_SHHS2_MESA_raw.npz\n",
      " - /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/eval_outputs_fresh_notebook/cm_shhs2.npy\n",
      " - /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/eval_outputs_fresh_notebook/cm_mesa.npy\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 9] Run evals + save SHHS2+MESA together\n",
    "OUT_DIR = ROOT / \"eval_outputs_fresh_notebook\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "val_m,  _      = eval_sequence_collect(model, val_seq_loader,  desc=\"VAL\")\n",
    "test_m, _      = eval_sequence_collect(model, test_seq_loader, desc=\"SHHS1 TEST\")\n",
    "shhs2_m, shhs2_raw = eval_sequence_collect(model, ext_seq_loader,  desc=\"SHHS2 EXT\")\n",
    "\n",
    "print_metrics(\"VAL\", val_m)\n",
    "print_metrics(\"SHHS1 TEST\", test_m)\n",
    "print_metrics(\"SHHS2 EXT\", shhs2_m)\n",
    "\n",
    "mesa_m, mesa_raw = (None, None)\n",
    "if mesa_seq_loader is not None:\n",
    "    mesa_m, mesa_raw = eval_sequence_collect(model, mesa_seq_loader, desc=\"MESA EXT\")\n",
    "    print_metrics(\"MESA EXT\", mesa_m)\n",
    "else:\n",
    "    print(\"\\n[MESA] mesa_seq_loader not found. (Skip)\")\n",
    "\n",
    "# --- save SHHS2 + MESA together (metrics + raw arrays)\n",
    "bundle = {\n",
    "    \"checkpoint\": str(BEST_CKPT),\n",
    "    \"shhs2_metrics\": shhs2_m,\n",
    "    \"mesa_metrics\": mesa_m,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# raw arrays saved in NPZ (compact)\n",
    "npz_path = OUT_DIR / \"EVAL_SHHS2_MESA_raw.npz\"\n",
    "save_dict = {\n",
    "    \"shhs2_y_true\": shhs2_raw[\"y_true\"] if shhs2_raw is not None else np.array([], dtype=np.int64),\n",
    "    \"shhs2_y_pred\": shhs2_raw[\"y_pred\"] if shhs2_raw is not None else np.array([], dtype=np.int64),\n",
    "    \"shhs2_probs\":  shhs2_raw[\"probs\"]  if shhs2_raw is not None else np.zeros((0, NUM_CLASSES), dtype=np.float32),\n",
    "}\n",
    "if mesa_raw is not None:\n",
    "    save_dict.update({\n",
    "        \"mesa_y_true\": mesa_raw[\"y_true\"],\n",
    "        \"mesa_y_pred\": mesa_raw[\"y_pred\"],\n",
    "        \"mesa_probs\":  mesa_raw[\"probs\"],\n",
    "    })\n",
    "else:\n",
    "    save_dict.update({\n",
    "        \"mesa_y_true\": np.array([], dtype=np.int64),\n",
    "        \"mesa_y_pred\": np.array([], dtype=np.int64),\n",
    "        \"mesa_probs\":  np.zeros((0, NUM_CLASSES), dtype=np.float32),\n",
    "    })\n",
    "\n",
    "np.savez_compressed(npz_path, **save_dict)\n",
    "\n",
    "# also save confusion matrices as .npy\n",
    "np.save(OUT_DIR / \"cm_shhs2.npy\", shhs2_m[\"cm\"])\n",
    "if mesa_m is not None:\n",
    "    np.save(OUT_DIR / \"cm_mesa.npy\", mesa_m[\"cm\"])\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", json_path)\n",
    "print(\" -\", npz_path)\n",
    "print(\" -\", OUT_DIR / \"cm_shhs2.npy\")\n",
    "print(\" -\", OUT_DIR / \"cm_mesa.npy\" if mesa_m is not None else \"(no mesa cm)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ddb295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== COMBINED (SHHS2 + MESA) =====\n",
      "epochs: SHHS2=2858985 | MESA=2210697 | total=5069682\n",
      "loss       : 1.0677\n",
      "acc        : 0.8267\n",
      "macro_f1   : 0.7496\n",
      "weighted_f1: 0.8274\n",
      "kappa      : 0.7562\n",
      "AUROC      : 0.9508\n",
      "AUPRC      : 0.7982\n",
      "meanConf   : 0.6759\n",
      "ECE        : 0.1508\n",
      "F1/class: {'W': 0.9030743596455058, 'N1': 0.4503597389424367, 'N2': 0.833533267853821, 'N3': 0.7017157627449399, 'REM': 0.8590734722414846}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[1523253   71311  107940    9361   55115]\n",
      " [  31242  133422   98515     204   29425]\n",
      " [  39945   79484 1633218   99097   55242]\n",
      " [   1980     154  142330  300254    1290]\n",
      " [  10083   15334   29794     847  600842]]\n"
     ]
    }
   ],
   "source": [
    "# %% [COMBINE ONLY] Use existing shhs2_m + mesa_m (no ext_m)\n",
    "\n",
    "# shhs2_m and mesa_m already exist in your globals (per your print)\n",
    "combo = combine_eval_metrics(shhs2_m, mesa_m)\n",
    "\n",
    "print(\"\\n===== COMBINED (SHHS2 + MESA) =====\")\n",
    "print(f\"epochs: SHHS2={combo['n_epochs_shhs2']} | MESA={combo['n_epochs_mesa']} | total={combo['n_epochs_total']}\")\n",
    "for k in [\"loss\",\"acc\",\"macro_f1\",\"weighted_f1\",\"kappa\",\"AUROC\",\"AUPRC\",\"meanConf\",\"ECE\"]:\n",
    "    print(f\"{k:11s}: {combo[k]:.4f}\")\n",
    "\n",
    "print(\"F1/class:\", combo[\"f1_per_class\"])\n",
    "print(\"Confusion Matrix labels:\", [LABELS[i] for i in range(NUM_CLASSES)])\n",
    "print(combo[\"cm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7c9cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [CELL 1] Minimal eval utilities (self-contained)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def _ece_from_probs(y_true, probs, n_bins=15):\n",
    "    conf = probs.max(axis=1)\n",
    "    pred = probs.argmax(axis=1)\n",
    "    acc = (pred == y_true).astype(np.float32)\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i + 1]\n",
    "        m = (conf >= lo) & (conf < hi)\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        ece += (m.mean()) * abs(acc[m].mean() - conf[m].mean())\n",
    "    return float(ece)\n",
    "\n",
    "def _auroc_auprc_multiclass(y_true, probs, num_classes):\n",
    "    Y = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "    aurocs, auprcs = [], []\n",
    "    for c in range(num_classes):\n",
    "        if Y[:, c].sum() == 0:\n",
    "            continue\n",
    "        try:\n",
    "            aurocs.append(roc_auc_score(Y[:, c], probs[:, c]))\n",
    "            auprcs.append(average_precision_score(Y[:, c], probs[:, c]))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if len(aurocs) == 0:\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "    return float(np.mean(aurocs)), float(np.mean(auprcs))\n",
    "\n",
    "def _print_metrics(tag, m):\n",
    "    print(f\"\\n===== {tag} =====\")\n",
    "    for k in [\"loss\",\"acc\",\"macro_f1\",\"kappa\",\"AUROC\",\"AUPRC\",\"meanConf\",\"ECE\"]:\n",
    "        if k in m:\n",
    "            print(f\"{k:9s}: {m[k]:.4f}\")\n",
    "    if \"bad_batches\" in m:\n",
    "        print(\"bad_batches:\", m[\"bad_batches\"])\n",
    "    if \"f1_per_class\" in m:\n",
    "        print(\"F1/class :\", m[\"f1_per_class\"])\n",
    "    if \"cm\" in m:\n",
    "        labs = [LABELS[i] for i in range(NUM_CLASSES)] if \"LABELS\" in globals() else list(range(NUM_CLASSES))\n",
    "        print(\"Confusion Matrix labels:\", labs)\n",
    "        print(m[\"cm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21245db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [CELL 2] eval_sequence_simple (no dependency on masked_loss_v5)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_sequence_simple(model, loader, desc=\"Eval\", num_classes=5, use_ce_loss=True):\n",
    "    model.eval()\n",
    "\n",
    "    all_true, all_pred, all_probs = [], [], []\n",
    "    total_loss = 0.0\n",
    "    total_n = 0\n",
    "    bad_batches = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=desc, leave=False):\n",
    "        # Support both dataset outputs:\n",
    "        # (xb,yb,mb) OR (xb,yb,mb,sb,db)\n",
    "        if len(batch) == 3:\n",
    "            xb, yb, mb = batch\n",
    "        else:\n",
    "            xb, yb, mb = batch[0], batch[1], batch[2]\n",
    "\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        mb = mb.to(device, non_blocking=True)\n",
    "\n",
    "        # Model forward: your V5.1 returns (main, aux, dur)\n",
    "        out = model(xb, mb)\n",
    "        if isinstance(out, (tuple, list)) and len(out) >= 1:\n",
    "            main_logits = out[0]\n",
    "        else:\n",
    "            main_logits = out\n",
    "\n",
    "        if not torch.isfinite(main_logits).all():\n",
    "            bad_batches += 1\n",
    "            continue\n",
    "\n",
    "        probs = torch.softmax(main_logits.float(), dim=-1)\n",
    "        pred = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        # valid positions only\n",
    "        yv = yb[mb].detach().cpu().numpy()\n",
    "        pv = pred[mb].detach().cpu().numpy()\n",
    "        pr = probs[mb].detach().cpu().numpy()\n",
    "\n",
    "        if yv.size == 0:\n",
    "            continue\n",
    "\n",
    "        all_true.append(yv)\n",
    "        all_pred.append(pv)\n",
    "        all_probs.append(pr)\n",
    "\n",
    "        if use_ce_loss:\n",
    "            # standard CE for logging only\n",
    "            logits_valid = main_logits[mb]              # (N,C)\n",
    "            y_valid = yb[mb]                            # (N,)\n",
    "            loss = F.cross_entropy(logits_valid, y_valid)\n",
    "            n = int(mb.sum().item())\n",
    "            total_loss += float(loss.item()) * n\n",
    "            total_n += n\n",
    "\n",
    "    if len(all_true) == 0:\n",
    "        return {\n",
    "            \"loss\": float(\"nan\"),\n",
    "            \"acc\": float(\"nan\"),\n",
    "            \"macro_f1\": float(\"nan\"),\n",
    "            \"kappa\": float(\"nan\"),\n",
    "            \"AUROC\": float(\"nan\"),\n",
    "            \"AUPRC\": float(\"nan\"),\n",
    "            \"meanConf\": float(\"nan\"),\n",
    "            \"ECE\": float(\"nan\"),\n",
    "            \"f1_per_class\": {LABELS[i]: float(\"nan\") for i in range(num_classes)},\n",
    "            \"cm\": np.zeros((num_classes, num_classes), dtype=np.int64),\n",
    "            \"bad_batches\": int(bad_batches),\n",
    "        }\n",
    "\n",
    "    y_true = np.concatenate(all_true)\n",
    "    y_pred = np.concatenate(all_pred)\n",
    "    probs_all = np.concatenate(all_probs)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "\n",
    "    auroc, auprc = _auroc_auprc_multiclass(y_true, probs_all, num_classes=num_classes)\n",
    "    mean_conf = float(probs_all.max(axis=1).mean())\n",
    "    ece = _ece_from_probs(y_true, probs_all, n_bins=15)\n",
    "\n",
    "    f1_per = {LABELS[i]: float(f1_score((y_true==i).astype(int), (y_pred==i).astype(int)))\n",
    "              for i in range(num_classes)}\n",
    "\n",
    "    return {\n",
    "        \"loss\": (total_loss / max(total_n, 1)) if use_ce_loss else float(\"nan\"),\n",
    "        \"acc\": float(acc),\n",
    "        \"macro_f1\": float(mf1),\n",
    "        \"kappa\": float(kappa),\n",
    "        \"AUROC\": auroc,\n",
    "        \"AUPRC\": auprc,\n",
    "        \"meanConf\": mean_conf,\n",
    "        \"ECE\": ece,\n",
    "        \"f1_per_class\": f1_per,\n",
    "        \"cm\": cm,\n",
    "        \"bad_batches\": int(bad_batches),\n",
    "        \"n_epochs\": int(len(y_true)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d133677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found NPZ: 12\n",
      "Example: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/inhouse_npz_shhs_style/sub1.npz\n",
      "Saved inhouse manifest: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/manifests/inhouse_12subj_manifest.csv\n",
      "SleepSequenceDataset[eval] files=12 max_hours=None normalize=True\n",
      "Built inhouse_seq_loader batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== INHOUSE (12 subj) =====\n",
      "loss     : 1.0821\n",
      "acc      : 0.6096\n",
      "macro_f1 : 0.5443\n",
      "kappa    : 0.4674\n",
      "AUROC    : 0.8609\n",
      "AUPRC    : 0.6095\n",
      "meanConf : 0.7280\n",
      "ECE      : 0.1186\n",
      "bad_batches: 0\n",
      "F1/class : {'W': 0.7451757864128998, 'N1': 0.33427533306419055, 'N2': 0.6250714204090961, 'N3': 0.2944120100083403, 'REM': 0.7226753670473084}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[2819  429  681   83  258]\n",
      " [ 117  414  200   20   69]\n",
      " [ 202  633 2735  408  165]\n",
      " [  57  132  973  353   18]\n",
      " [ 101   49   19    1  886]]\n",
      "Saved: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/eval_bundles/EVAL_INHOUSE_12.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# %% [CELL 3] Build inhouse loader + evaluate + save\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "INHOUSE_DIR = Path(\"/data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/inhouse_npz_shhs_style/\")\n",
    "assert INHOUSE_DIR.exists(), f\"Not found: {INHOUSE_DIR}\"\n",
    "\n",
    "npz_files = sorted(INHOUSE_DIR.glob(\"*.npz\"))\n",
    "assert len(npz_files) > 0, \"No .npz files found in the inhouse folder.\"\n",
    "print(\"Found NPZ:\", len(npz_files))\n",
    "print(\"Example:\", npz_files[0])\n",
    "\n",
    "def _infer_subject_id(p: Path):\n",
    "    s = p.stem\n",
    "    s = re.sub(r\"_inhouse$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "# Save a small manifest (safe)\n",
    "inhouse_manifest_path = ROOT / \"manifests\" / \"inhouse_12subj_manifest.csv\"\n",
    "inhouse_manifest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_inhouse = pd.DataFrame({\n",
    "    \"subject_id\": [_infer_subject_id(p) for p in npz_files],\n",
    "    \"npz_path\": [str(p) for p in npz_files],\n",
    "    \"split\": [\"inhouse\"] * len(npz_files),\n",
    "})\n",
    "df_inhouse.to_csv(inhouse_manifest_path, index=False)\n",
    "print(\"Saved inhouse manifest:\", inhouse_manifest_path)\n",
    "\n",
    "# Build dataset using your existing class\n",
    "df_inhouse2 = pd.read_csv(inhouse_manifest_path)\n",
    "inhouse_ds = SleepSequenceDataset(df_inhouse2, mode=\"eval\", max_hours=None, augmentor=None, do_normalize=True)\n",
    "\n",
    "# IMPORTANT: use the SAME collate as your main loaders\n",
    "# In your code it is called collate_pad\n",
    "assert \"collate_pad\" in globals(), \"collate_pad not found. Run the cell where collate_pad is defined.\"\n",
    "inhouse_seq_loader = DataLoader(\n",
    "    inhouse_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_pad,\n",
    ")\n",
    "\n",
    "print(\"Built inhouse_seq_loader batches:\", len(inhouse_seq_loader))\n",
    "\n",
    "# Evaluate\n",
    "inhouse_m = eval_sequence_simple(model, inhouse_seq_loader, desc=\"INHOUSE (12 subj)\", num_classes=NUM_CLASSES, use_ce_loss=True)\n",
    "_print_metrics(\"INHOUSE (12 subj)\", inhouse_m)\n",
    "\n",
    "# ---------- save (JSON-safe) ----------\n",
    "def to_jsonable(obj):\n",
    "    import numpy as np\n",
    "    if obj is None: return None\n",
    "    if isinstance(obj, (str, int, float, bool)): return obj\n",
    "    if isinstance(obj, (np.integer,)): return int(obj)\n",
    "    if isinstance(obj, (np.floating,)): return float(obj)\n",
    "    if isinstance(obj, (np.ndarray,)): return obj.tolist()\n",
    "    if isinstance(obj, dict): return {str(k): to_jsonable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)): return [to_jsonable(v) for v in obj]\n",
    "    return str(obj)\n",
    "\n",
    "OUT_DIR = ROOT / \"eval_bundles\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = OUT_DIR / \"EVAL_INHOUSE_12.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(to_jsonable({\"inhouse_metrics\": inhouse_m, \"inhouse_manifest\": str(inhouse_manifest_path)}), f, indent=2)\n",
    "\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "611664ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### real world deployemnt analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2aa807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params:\n",
      "  total params     : 22,905,512 (22.906 M)\n",
      "  trainable params : 22,905,512 (22.906 M)\n",
      "  FP32 param size  : 87.38 MB\n",
      "  FP16 param size  : 43.69 MB\n",
      "Checkpoint file size: 349.79 MB  (BEST_VAL_macroF1.pt)\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL] Model size / parameter counts\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "total_params, trainable_params = count_params(model)\n",
    "\n",
    "# Rough FP32 size on disk if stored as raw parameters (not checkpoint overhead)\n",
    "fp32_param_bytes = total_params * 4\n",
    "fp16_param_bytes = total_params * 2\n",
    "\n",
    "print(\"Model params:\")\n",
    "print(f\"  total params     : {total_params:,} ({total_params/1e6:.3f} M)\")\n",
    "print(f\"  trainable params : {trainable_params:,} ({trainable_params/1e6:.3f} M)\")\n",
    "print(f\"  FP32 param size  : {fp32_param_bytes/1024**2:.2f} MB\")\n",
    "print(f\"  FP16 param size  : {fp16_param_bytes/1024**2:.2f} MB\")\n",
    "\n",
    "# If you have a best checkpoint path (optional)\n",
    "if \"BEST_CKPT\" in globals():\n",
    "    ckpt_path = Path(BEST_CKPT)\n",
    "    if ckpt_path.exists():\n",
    "        print(f\"Checkpoint file size: {ckpt_path.stat().st_size/1024**2:.2f} MB  ({ckpt_path.name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "693c76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inference Efficiency ===\n",
      "device                : cuda\n",
      "use_amp               : True\n",
      "n_subjects_tested     : 12\n",
      "n_runs                : 10\n",
      "ms_per_subject_mean   : 95.66590481748183\n",
      "ms_per_subject_std    : 24.166755547636562\n",
      "ms_per_epoch_mean     : 1148.9899184554815\n",
      "ms_per_epoch_std      : 2.3279415758547057\n",
      "subjects_per_sec      : 10.453044916136744\n",
      "peak_mem_allocated_MB : 1403.85107421875\n",
      "peak_mem_reserved_MB  : 11528.0\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL] Inference latency + GPU memory benchmark (sequence-level)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _forward_main_logits(model, xb, mb):\n",
    "    out = model(xb, mb)\n",
    "    if isinstance(out, (tuple, list)):\n",
    "        return out[0]  # main logits\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_inference_sequence_loader(\n",
    "    model,\n",
    "    loader,\n",
    "    device,\n",
    "    n_warmup=5,\n",
    "    n_runs=20,\n",
    "    max_batches=None,\n",
    "    use_amp=True,\n",
    "    desc=\"BENCH\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Measures end-to-end inference over 'max_batches' subjects in loader.\n",
    "    Returns ms/subject and ms/epoch (epoch=one pass over chosen batches).\n",
    "    Also reports peak GPU memory footprint during inference.\n",
    "    \"\"\"\n",
    "    assert device.type in [\"cuda\", \"cpu\"]\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # pick batches to test (keep it deterministic)\n",
    "    batches = []\n",
    "    for i, batch in enumerate(loader):\n",
    "        batches.append(batch)\n",
    "        if max_batches is not None and len(batches) >= max_batches:\n",
    "            break\n",
    "    assert len(batches) > 0, \"Loader produced 0 batches.\"\n",
    "\n",
    "    # ---- warmup (GPU only matters)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    for _ in range(n_warmup):\n",
    "        for batch in batches:\n",
    "            xb, yb, mb = batch[0], batch[1], batch[2]\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            mb = mb.to(device, non_blocking=True)\n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                    _ = _forward_main_logits(model, xb, mb)\n",
    "            else:\n",
    "                _ = _forward_main_logits(model, xb, mb)\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # ---- timed runs\n",
    "    epoch_times = []\n",
    "    subj_times = []\n",
    "\n",
    "    for r in range(n_runs):\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        n_subj = 0\n",
    "\n",
    "        for batch in batches:\n",
    "            xb, yb, mb = batch[0], batch[1], batch[2]\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            mb = mb.to(device, non_blocking=True)\n",
    "\n",
    "            ts = time.perf_counter()\n",
    "            if device.type == \"cuda\":\n",
    "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                    logits = _forward_main_logits(model, xb, mb)\n",
    "            else:\n",
    "                logits = _forward_main_logits(model, xb, mb)\n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            te = time.perf_counter()\n",
    "\n",
    "            subj_times.append((te - ts) * 1000.0)  # ms per subject\n",
    "            n_subj += 1\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        epoch_times.append((t1 - t0) * 1000.0)  # ms per pass over chosen subjects\n",
    "\n",
    "    # memory stats (GPU)\n",
    "    if device.type == \"cuda\":\n",
    "        peak_alloc = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        peak_reserved = torch.cuda.max_memory_reserved() / 1024**2\n",
    "    else:\n",
    "        peak_alloc = float(\"nan\")\n",
    "        peak_reserved = float(\"nan\")\n",
    "\n",
    "    epoch_times = np.array(epoch_times, dtype=np.float64)\n",
    "    subj_times = np.array(subj_times, dtype=np.float64)\n",
    "\n",
    "    out = {\n",
    "        \"device\": str(device),\n",
    "        \"use_amp\": bool(use_amp),\n",
    "        \"n_subjects_tested\": int(len(batches)),\n",
    "        \"n_runs\": int(n_runs),\n",
    "        \"n_warmup\": int(n_warmup),\n",
    "\n",
    "        \"ms_per_epoch_mean\": float(epoch_times.mean()),\n",
    "        \"ms_per_epoch_std\": float(epoch_times.std(ddof=1) if len(epoch_times) > 1 else 0.0),\n",
    "\n",
    "        \"ms_per_subject_mean\": float(subj_times.mean()),\n",
    "        \"ms_per_subject_std\": float(subj_times.std(ddof=1) if len(subj_times) > 1 else 0.0),\n",
    "\n",
    "        \"subjects_per_sec\": float(1000.0 / max(subj_times.mean(), 1e-9)),\n",
    "        \"peak_mem_allocated_MB\": float(peak_alloc),\n",
    "        \"peak_mem_reserved_MB\": float(peak_reserved),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# Choose a loader to benchmark:\n",
    "# - inhouse_seq_loader (12 subjects) is perfect for \"real-world\" local feasibility\n",
    "loader_for_bench = inhouse_seq_loader if \"inhouse_seq_loader\" in globals() else val_seq_loader\n",
    "\n",
    "bench = benchmark_inference_sequence_loader(\n",
    "    model,\n",
    "    loader_for_bench,\n",
    "    device=device,\n",
    "    n_warmup=3,\n",
    "    n_runs=10,\n",
    "    max_batches=12,     # use 12 if inhouse, else you can set 50 etc.\n",
    "    use_amp=(device.type==\"cuda\"),\n",
    "    desc=\"BENCH\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Inference Efficiency ===\")\n",
    "for k in [\"device\",\"use_amp\",\"n_subjects_tested\",\"n_runs\",\"ms_per_subject_mean\",\"ms_per_subject_std\",\n",
    "          \"ms_per_epoch_mean\",\"ms_per_epoch_std\",\"subjects_per_sec\",\n",
    "          \"peak_mem_allocated_MB\",\"peak_mem_reserved_MB\"]:\n",
    "    print(f\"{k:22s}: {bench[k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bb44a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested paper sentence:\n",
      "We report computational efficiency including model size (22.91M params), inference latency (95.6724.17 ms/recording), and memory footprint (peak GPU mem 1403.9 MB allocated (11528.0 MB reserved)) to assess feasibility for deployment on resource-constrained platforms.\n",
      "\n",
      "Table row (example):\n",
      "Model | Params | Latency | Peak Mem\n",
      "Ours  | 22.91M params | 95.6724.17 ms/recording | 1403.9 MB\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL] Paper-ready reporting text\n",
    "\n",
    "def fmt(mean, std, unit=\"ms\"):\n",
    "    return f\"{mean:.2f}{std:.2f} {unit}\"\n",
    "\n",
    "total_params, trainable_params = sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model_size_str = f\"{total_params/1e6:.2f}M params\"\n",
    "lat_str = fmt(bench[\"ms_per_subject_mean\"], bench[\"ms_per_subject_std\"], \"ms/recording\")\n",
    "epoch_str = fmt(bench[\"ms_per_epoch_mean\"], bench[\"ms_per_epoch_std\"], \"ms per {N} recordings\").replace(\"{N}\", str(bench[\"n_subjects_tested\"]))\n",
    "\n",
    "mem_alloc = bench[\"peak_mem_allocated_MB\"]\n",
    "mem_res = bench[\"peak_mem_reserved_MB\"]\n",
    "mem_str = f\"peak GPU mem {mem_alloc:.1f} MB allocated ({mem_res:.1f} MB reserved)\"\n",
    "\n",
    "print(\"Suggested paper sentence:\")\n",
    "print(\n",
    "    f\"We report computational efficiency including model size ({model_size_str}), \"\n",
    "    f\"inference latency ({lat_str}), and memory footprint ({mem_str}) \"\n",
    "    f\"to assess feasibility for deployment on resource-constrained platforms.\"\n",
    ")\n",
    "\n",
    "print(\"\\nTable row (example):\")\n",
    "print(f\"Model | Params | Latency | Peak Mem\")\n",
    "print(f\"Ours  | {model_size_str} | {lat_str} | {mem_alloc:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66cec3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## real world infrance analysis  cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0bda07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU threads: 16 | interop: 2\n",
      "\n",
      "=== CPU Inference Efficiency ===\n",
      "device                : cpu\n",
      "use_amp               : False\n",
      "n_subjects_tested     : 3\n",
      "n_runs                : 3\n",
      "ms_per_subject_mean   : 3184.3750653788447\n",
      "ms_per_subject_std    : 354.2850801274565\n",
      "ms_per_epoch_mean     : 9553.179225884378\n",
      "ms_per_epoch_std      : 61.86108768615994\n",
      "subjects_per_sec      : 0.31403335959767986\n",
      "peak_mem_allocated_MB : nan\n",
      "peak_mem_reserved_MB  : nan\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL] CPU benchmark (same loader) + optional thread control\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# ---- optional: control CPU threads (choose one)\n",
    "# If you want max speed on CPU, try setting these BEFORE running benchmark.\n",
    "# Start with 8 or 16 depending on your server.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"16\"\n",
    "torch.set_num_threads(16)\n",
    "torch.set_num_interop_threads(2)\n",
    "\n",
    "print(\"CPU threads:\", torch.get_num_threads(), \"| interop:\", torch.get_num_interop_threads())\n",
    "\n",
    "# Use SAME loader you used for GPU\n",
    "loader_for_bench = inhouse_seq_loader  # 12 subjects\n",
    "\n",
    "# Create CPU copy of model (so you don't move your GPU model)\n",
    "model_cpu = type(model)(**model.__dict__.get('_init_kwargs', {})) if False else None\n",
    "# ^ ignore that line; we do a safe deepcopy approach below\n",
    "\n",
    "import copy\n",
    "model_cpu = copy.deepcopy(model).to(\"cpu\")\n",
    "model_cpu.eval()\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "bench_cpu = benchmark_inference_sequence_loader(\n",
    "    model_cpu,\n",
    "    loader_for_bench,\n",
    "    device=device_cpu,\n",
    "    n_warmup=1,\n",
    "    n_runs=3,\n",
    "    max_batches=3,        # start small; increase later to 12\n",
    "    use_amp=False,\n",
    "    desc=\"CPU_BENCH\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== CPU Inference Efficiency ===\")\n",
    "for k in [\"device\",\"use_amp\",\"n_subjects_tested\",\"n_runs\",\"ms_per_subject_mean\",\"ms_per_subject_std\",\n",
    "          \"ms_per_epoch_mean\",\"ms_per_epoch_std\",\"subjects_per_sec\",\n",
    "          \"peak_mem_allocated_MB\",\"peak_mem_reserved_MB\"]:\n",
    "    print(f\"{k:22s}: {bench_cpu[k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67b6db5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Device</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Latency (ms/subject)</th>\n",
       "      <th>Epoch time (ms)</th>\n",
       "      <th>Throughput (subj/s)</th>\n",
       "      <th>Peak mem alloc (MB)</th>\n",
       "      <th>Peak mem reserved (MB)</th>\n",
       "      <th>AMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPU</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>95.67  24.17</td>\n",
       "      <td>1148.99  2.33</td>\n",
       "      <td>10.45</td>\n",
       "      <td>1403.9</td>\n",
       "      <td>11528.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPU</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3184.38  354.29</td>\n",
       "      <td>9553.18  61.86</td>\n",
       "      <td>0.31</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Device  Subjects  Runs Latency (ms/subject)  Epoch time (ms)  \\\n",
       "0    GPU        12    10        95.67  24.17   1148.99  2.33   \n",
       "1    CPU         3     3     3184.38  354.29  9553.18  61.86   \n",
       "\n",
       "  Throughput (subj/s) Peak mem alloc (MB) Peak mem reserved (MB)    AMP  \n",
       "0               10.45              1403.9                11528.0   True  \n",
       "1                0.31                 N/A                    N/A  False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [CELL] Side-by-side comparison (GPU vs CPU)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def row_from_bench(name, b):\n",
    "    return {\n",
    "        \"Device\": name,\n",
    "        \"Subjects\": b[\"n_subjects_tested\"],\n",
    "        \"Runs\": b[\"n_runs\"],\n",
    "        \"Latency (ms/subject)\": f\"{b['ms_per_subject_mean']:.2f}  {b['ms_per_subject_std']:.2f}\",\n",
    "        \"Epoch time (ms)\": f\"{b['ms_per_epoch_mean']:.2f}  {b['ms_per_epoch_std']:.2f}\",\n",
    "        \"Throughput (subj/s)\": f\"{b['subjects_per_sec']:.2f}\",\n",
    "        \"Peak mem alloc (MB)\": f\"{b['peak_mem_allocated_MB']:.1f}\" if b[\"peak_mem_allocated_MB\"]==b[\"peak_mem_allocated_MB\"] else \"N/A\",\n",
    "        \"Peak mem reserved (MB)\": f\"{b['peak_mem_reserved_MB']:.1f}\" if b[\"peak_mem_reserved_MB\"]==b[\"peak_mem_reserved_MB\"] else \"N/A\",\n",
    "        \"AMP\": b[\"use_amp\"],\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "rows.append(row_from_bench(\"GPU\", bench))\n",
    "rows.append(row_from_bench(\"CPU\", bench_cpu))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e66f83c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We report computational efficiency metrics including model size (22.91M parameters), inference latency on GPU (95.724.2 ms/recording) and CPU (3184.4354.3 ms/recording), and GPU memory footprint (1404 MB allocated (11528 MB reserved)), providing insights into feasibility on resource-constrained platforms.\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL] Paper-ready text (GPU + CPU)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "gpu_lat = f\"{bench['ms_per_subject_mean']:.1f}{bench['ms_per_subject_std']:.1f} ms/recording\"\n",
    "cpu_lat = f\"{bench_cpu['ms_per_subject_mean']:.1f}{bench_cpu['ms_per_subject_std']:.1f} ms/recording\"\n",
    "\n",
    "gpu_mem = f\"{bench['peak_mem_allocated_MB']:.0f} MB allocated ({bench['peak_mem_reserved_MB']:.0f} MB reserved)\"\n",
    "# CPU mem not measured by torch; report as \"N/A\" unless you want psutil-based RSS\n",
    "print(\n",
    "    f\"We report computational efficiency metrics including model size ({total_params/1e6:.2f}M parameters), \"\n",
    "    f\"inference latency on GPU ({gpu_lat}) and CPU ({cpu_lat}), and GPU memory footprint \"\n",
    "    f\"({gpu_mem}), providing insights into feasibility on resource-constrained platforms.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a415d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
