{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e535f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Visible CUDA devices: 1\n",
      "Using device: cuda\n",
      "GPU: NVIDIA RTX A6000\n",
      "Rows: 9868\n",
      "cohort  split        \n",
      "MESA    external_test    1856\n",
      "SHHS1   test              548\n",
      "        train            4380\n",
      "        val               548\n",
      "SHHS2   external_test    2536\n",
      "dtype: int64\n",
      "SHHS1 TEST subjects: 548\n",
      "Model params (M): 22.905512\n",
      "Loading: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/checkpoints_hier_rope_seq_v5_1/BEST_VAL_macroF1.pt\n",
      "Loaded model_state. missing: 0 | unexpected: 0\n",
      "Applied EMA shadow tensors: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict SHHS1 TEST full nights: 100%|█████████| 548/548 [02:24<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected: 548 subjects\n",
      "Plotting + metrics helpers ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>E</th>\n",
       "      <th>TST_gt</th>\n",
       "      <th>TST_pred</th>\n",
       "      <th>SE_gt</th>\n",
       "      <th>SE_pred</th>\n",
       "      <th>SOL_gt</th>\n",
       "      <th>SOL_pred</th>\n",
       "      <th>WASO_gt</th>\n",
       "      <th>WASO_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>N2_diff</th>\n",
       "      <th>N2_abs</th>\n",
       "      <th>N3_diff</th>\n",
       "      <th>N3_abs</th>\n",
       "      <th>REM_diff</th>\n",
       "      <th>REM_abs</th>\n",
       "      <th>REMpct_diff</th>\n",
       "      <th>REMpct_abs</th>\n",
       "      <th>N3pct_diff</th>\n",
       "      <th>N3pct_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shhs1-200018_v1</td>\n",
       "      <td>1004</td>\n",
       "      <td>305.5</td>\n",
       "      <td>308.5</td>\n",
       "      <td>60.856574</td>\n",
       "      <td>61.454183</td>\n",
       "      <td>112.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.529864</td>\n",
       "      <td>4.529864</td>\n",
       "      <td>4.134360</td>\n",
       "      <td>4.134360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shhs1-200021_v1</td>\n",
       "      <td>992</td>\n",
       "      <td>319.0</td>\n",
       "      <td>331.5</td>\n",
       "      <td>64.314516</td>\n",
       "      <td>66.834677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>164.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-4.264127</td>\n",
       "      <td>4.264127</td>\n",
       "      <td>-1.087959</td>\n",
       "      <td>1.087959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shhs1-200035_v1</td>\n",
       "      <td>1004</td>\n",
       "      <td>373.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>74.302789</td>\n",
       "      <td>78.087649</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>5.684740</td>\n",
       "      <td>5.684740</td>\n",
       "      <td>-2.570170</td>\n",
       "      <td>2.570170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shhs1-200039_v1</td>\n",
       "      <td>879</td>\n",
       "      <td>367.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>83.503982</td>\n",
       "      <td>85.779295</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.500871</td>\n",
       "      <td>0.500871</td>\n",
       "      <td>5.546802</td>\n",
       "      <td>5.546802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shhs1-200043_v1</td>\n",
       "      <td>759</td>\n",
       "      <td>365.5</td>\n",
       "      <td>363.0</td>\n",
       "      <td>96.310935</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.5</td>\n",
       "      <td>65.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>8.499244</td>\n",
       "      <td>8.499244</td>\n",
       "      <td>3.862214</td>\n",
       "      <td>3.862214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id     E  TST_gt  TST_pred      SE_gt    SE_pred  SOL_gt  \\\n",
       "0  shhs1-200018_v1  1004   305.5     308.5  60.856574  61.454183   112.5   \n",
       "1  shhs1-200021_v1   992   319.0     331.5  64.314516  66.834677     0.0   \n",
       "2  shhs1-200035_v1  1004   373.0     392.0  74.302789  78.087649    31.0   \n",
       "3  shhs1-200039_v1   879   367.0     377.0  83.503982  85.779295    23.5   \n",
       "4  shhs1-200043_v1   759   365.5     363.0  96.310935  95.652174     0.0   \n",
       "\n",
       "   SOL_pred  WASO_gt  WASO_pred  ...  N2_diff  N2_abs  N3_diff  N3_abs  \\\n",
       "0      65.0     84.0      128.5  ...    -29.0    29.0     13.0    13.0   \n",
       "1       0.0    177.0      164.5  ...     34.0    34.0     -2.0     2.0   \n",
       "2       0.0     98.0      110.0  ...      0.5     0.5     -6.0     6.0   \n",
       "3      23.5     49.0       39.0  ...    -18.5    18.5     23.5    23.5   \n",
       "4       0.0     14.0       16.5  ...    -65.5    65.5     13.5    13.5   \n",
       "\n",
       "   REM_diff  REM_abs  REMpct_diff  REMpct_abs  N3pct_diff  N3pct_abs  \n",
       "0      14.5     14.5     4.529864    4.529864    4.134360   4.134360  \n",
       "1     -12.0     12.0    -4.264127    4.264127   -1.087959   1.087959  \n",
       "2      24.5     24.5     5.684740    5.684740   -2.570170   2.570170  \n",
       "3       1.0      1.0    -0.500871    0.500871    5.546802   5.546802  \n",
       "4      30.5     30.5     8.499244    8.499244    3.862214   3.862214  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/akbar1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 150 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/anaconda3/envs/akbar1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 150 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Night-level absolute error summary (mean ± std):\n",
      "TST    | MAE=10.12 ± 12.80\n",
      "SE     | MAE=2.17 ± 2.79\n",
      "SOL    | MAE=6.00 ± 16.12\n",
      "WASO   | MAE=10.85 ± 14.81\n",
      "N3     | MAE=15.52 ± 15.89\n",
      "REM    | MAE=10.36 ± 12.99\n",
      "N3pct  | MAE=4.20 ± 4.29\n",
      "REMpct | MAE=2.74 ± 3.49\n",
      "Saved CSV: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test/night_metrics_gt_vs_pred.csv\n",
      "Saved BlandAltman plots to: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test\n",
      "Saved hypnogram PNGs: 6 files\n",
      "Output folder: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test\n",
      "\n",
      "===== SHHS1 TEST (epoch-level) =====\n",
      "acc      : 0.8656\n",
      "macro_f1 : 0.8109\n",
      "kappa    : 0.8144\n",
      "F1/class : {'W': 0.9216522245838207, 'N1': 0.5367519943346316, 'N2': 0.8737516650298247, 'N3': 0.8319557044407884, 'REM': 0.8902049606416158}\n",
      "Confusion Matrix labels: ['W', 'N1', 'N2', 'N3', 'REM']\n",
      "[[109925   5916   3969    418   2185]\n",
      " [  1901  12885   3317     12   1730]\n",
      " [  3515   7522 187276  16349   8877]\n",
      " [   117     10   8324  62957    167]\n",
      " [   668   1833   2246     36  71925]]\n",
      "Saved epoch-level summary: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test/epoch_level_summary.json\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL 0] Standalone SHHS1 TEST night-level analysis:\n",
    "# - Full-night hypnograms (GT vs Pred)\n",
    "# - Night metrics (TST, SE, SOL, WASO, stage minutes/%)\n",
    "# - BlandAltman plots (TST, SE, WASO, SOL)\n",
    "# - Saves CSV + figures\n",
    "\n",
    "import os, json, math, random, re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# (A) GPU + seed\n",
    "# ----------------------------\n",
    "# IMPORTANT: CUDA_VISIBLE_DEVICES indexes the GPUs visible to the machine.\n",
    "# If you want \"the 1st visible GPU\", set it to \"0\".\n",
    "# If your machine has GPUs [0..3], setting \"4\" is invalid.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # change if needed\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Visible CUDA devices:\", torch.cuda.device_count())\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "# %% [CELL 1] Paths + load manifest (SHHS1 test only)\n",
    "\n",
    "ROOT = Path(\"/data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/\")\n",
    "MANIFEST_PATH = ROOT / \"manifest_sleepstaging_planA.csv\"\n",
    "assert MANIFEST_PATH.exists(), f\"Missing manifest: {MANIFEST_PATH}\"\n",
    "\n",
    "manifest = pd.read_csv(MANIFEST_PATH)\n",
    "print(\"Rows:\", len(manifest))\n",
    "print(manifest.groupby([\"cohort\",\"split\"]).size())\n",
    "\n",
    "df_test = manifest[(manifest.cohort==\"SHHS1\") & (manifest.split==\"test\")].copy()\n",
    "print(\"SHHS1 TEST subjects:\", len(df_test))\n",
    "\n",
    "\n",
    "# %% [CELL 2] Normalization + learned smoothing helpers (minimal)\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "LABELS = {0:\"W\", 1:\"N1\", 2:\"N2\", 3:\"N3\", 4:\"REM\"}\n",
    "EPOCH_SEC = 30.0\n",
    "FS = 125\n",
    "T = 3750  # 30s * 125Hz\n",
    "\n",
    "def normalize_epochs_zscore(x, eps=1e-6, clip=10.0):\n",
    "    mu = np.mean(x, axis=1, keepdims=True)\n",
    "    sd = np.std(x, axis=1, keepdims=True) + eps\n",
    "    x = (x - mu) / sd\n",
    "    if clip is not None:\n",
    "        x = np.clip(x, -clip, clip)\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def apply_learned_smoothing_probs(probs, trans_logits):\n",
    "    # probs: (B,L,C), trans_logits: (C,C)\n",
    "    Tm = torch.softmax(trans_logits, dim=1)\n",
    "    return probs @ Tm\n",
    "\n",
    "\n",
    "# %% [CELL 3] Model definition (your HierSleepTransformerV5_1)\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.drop_prob = float(drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if (not self.training) or self.drop_prob == 0.0:\n",
    "            return x\n",
    "        keep = 1.0 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        rand = keep + torch.rand(shape, device=x.device)\n",
    "        mask = torch.floor(rand)\n",
    "        return x / keep * mask\n",
    "\n",
    "class ResConv1D(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k, s=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(c_in, c_out, k, stride=s, padding=k//2),\n",
    "            nn.BatchNorm1d(c_out),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(c_out, c_out, k, padding=k//2),\n",
    "            nn.BatchNorm1d(c_out),\n",
    "        )\n",
    "        self.skip = nn.Conv1d(c_in, c_out, 1, stride=s) if (c_in != c_out or s != 1) else nn.Identity()\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x) + self.skip(x))\n",
    "\n",
    "class EpochEncoder(nn.Module):\n",
    "    def __init__(self, d_model=384):\n",
    "        super().__init__()\n",
    "        self.branch_short = ResConv1D(1, 128, k=7,  s=4)\n",
    "        self.branch_mid   = ResConv1D(1, 128, k=15, s=4)\n",
    "        self.branch_long  = ResConv1D(1, 128, k=31, s=4)\n",
    "\n",
    "        self.freq_proj = nn.Sequential(\n",
    "            nn.Linear(1876, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Linear(128*3 + 256, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,L,1,T)\n",
    "        B, L, _, T_ = x.shape\n",
    "        x = x.view(B*L, 1, T_)\n",
    "\n",
    "        zs = self.branch_short(x).mean(-1)\n",
    "        zm = self.branch_mid(x).mean(-1)\n",
    "        zl = self.branch_long(x).mean(-1)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            xf32 = x.squeeze(1).float()\n",
    "            Xf = torch.fft.rfft(xf32, dim=-1)\n",
    "            mag = torch.abs(Xf)\n",
    "            mag = mag[:, :1876]\n",
    "            mag = torch.log1p(mag)\n",
    "            mag = mag / (mag.mean(dim=1, keepdim=True) + 1e-6)\n",
    "\n",
    "        zf = self.freq_proj(mag)\n",
    "        z = torch.cat([zs, zm, zl, zf.to(zs.dtype)], dim=-1)\n",
    "        z = self.fuse(z)\n",
    "        return z.view(B, L, -1)\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1 = x[..., ::2]\n",
    "    x2 = x[..., 1::2]\n",
    "    return torch.stack((-x2, x1), dim=-1).flatten(-2)\n",
    "\n",
    "class RoPE(nn.Module):\n",
    "    def __init__(self, head_dim, base=10000):\n",
    "        super().__init__()\n",
    "        assert head_dim % 2 == 0\n",
    "        self.head_dim = head_dim\n",
    "        self.base = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,L,H,Dh)\n",
    "        B, L, H, Dh = x.shape\n",
    "        half = Dh // 2\n",
    "        freqs = 1.0 / (self.base ** (torch.arange(half, device=x.device) / half))\n",
    "        t = torch.arange(L, device=x.device)\n",
    "        angles = torch.einsum(\"l,d->ld\", t, freqs)\n",
    "        cos = torch.cos(angles)[None, :, None, :]\n",
    "        sin = torch.sin(angles)[None, :, None, :]\n",
    "        cos = cos.repeat_interleave(2, dim=-1)\n",
    "        sin = sin.repeat_interleave(2, dim=-1)\n",
    "        return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "def _windows(L, w):\n",
    "    out = []\n",
    "    s = 0\n",
    "    while s < L:\n",
    "        e = min(L, s + w)\n",
    "        out.append((s, e))\n",
    "        s = e\n",
    "    return out\n",
    "\n",
    "class MultiHeadSelfAttentionRoPE_LocalGlobal(nn.Module):\n",
    "    def __init__(self, d_model=384, n_heads=8, dropout=0.1, window_size=64):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.window_size = int(window_size)\n",
    "\n",
    "        self.qkv = nn.Linear(d_model, 3*d_model)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.rope = RoPE(self.d_head)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None, global_attn=False):\n",
    "        # x: (B,L,D), key_padding_mask: (B,L)\n",
    "        B, L, D = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        q = q.view(B, L, self.n_heads, self.d_head)\n",
    "        k = k.view(B, L, self.n_heads, self.d_head)\n",
    "        v = v.view(B, L, self.n_heads, self.d_head)\n",
    "\n",
    "        q = self.rope(q)\n",
    "        k = self.rope(k)\n",
    "\n",
    "        q = q.transpose(1, 2)  # (B,H,L,Dh)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        if global_attn or self.window_size >= L:\n",
    "            scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "            scores = scores.float()\n",
    "            if key_padding_mask is not None:\n",
    "                scores = scores.masked_fill(~key_padding_mask[:, None, None, :], -1e9)\n",
    "            attn = torch.softmax(scores, dim=-1)\n",
    "            attn = self.drop(attn).to(v.dtype)\n",
    "            out = attn @ v\n",
    "            out = out.transpose(1, 2).contiguous().view(B, L, D)\n",
    "            return self.proj(out)\n",
    "\n",
    "        w = self.window_size\n",
    "        out = torch.zeros((B, self.n_heads, L, self.d_head), device=x.device, dtype=v.dtype)\n",
    "\n",
    "        for (s, e) in _windows(L, w):\n",
    "            qs = q[:, :, s:e, :]\n",
    "            ks = k[:, :, s:e, :]\n",
    "            vs = v[:, :, s:e, :]\n",
    "\n",
    "            scores = (qs @ ks.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "            scores = scores.float()\n",
    "            if key_padding_mask is not None:\n",
    "                m = key_padding_mask[:, s:e]\n",
    "                scores = scores.masked_fill(~m[:, None, None, :], -1e9)\n",
    "\n",
    "            attn = torch.softmax(scores, dim=-1)\n",
    "            attn = self.drop(attn).to(vs.dtype)\n",
    "            out[:, :, s:e, :] = attn @ vs\n",
    "\n",
    "        out = out.transpose(1, 2).contiguous().view(B, L, D)\n",
    "        return self.proj(out)\n",
    "\n",
    "class TransformerBlockLG(nn.Module):\n",
    "    def __init__(self, d_model=384, n_heads=8, drop=0.1, drop_path=0.1, window_size=64):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.attn = MultiHeadSelfAttentionRoPE_LocalGlobal(d_model, n_heads, drop, window_size=window_size)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, 4*d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(4*d_model, d_model),\n",
    "        )\n",
    "        self.dp = DropPath(drop_path)\n",
    "\n",
    "    def forward(self, x, mask, global_attn=False):\n",
    "        x = x + self.dp(self.attn(self.ln1(x), key_padding_mask=mask, global_attn=global_attn))\n",
    "        x = x + self.dp(self.mlp(self.ln2(x)))\n",
    "        return x\n",
    "\n",
    "class HierSleepTransformerV5_1(nn.Module):\n",
    "    def __init__(self, num_classes=5, d_model=384, depth=12, n_heads=8,\n",
    "                 dur_bins=8, window_size=64, global_every=3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.dur_bins = dur_bins\n",
    "        self.depth = int(depth)\n",
    "        self.global_every = int(global_every)\n",
    "\n",
    "        self.encoder = EpochEncoder(d_model)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlockLG(\n",
    "                d_model=d_model,\n",
    "                n_heads=n_heads,\n",
    "                drop=0.1,\n",
    "                drop_path=0.1*(i+1)/depth,\n",
    "                window_size=window_size\n",
    "            )\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "        self.head = nn.Linear(d_model, num_classes)\n",
    "\n",
    "        # aux heads (not needed for inference but exist in checkpoint)\n",
    "        self.aux_n1 = nn.Linear(d_model, 2)\n",
    "        self.aux_dur = nn.Linear(d_model, dur_bins)\n",
    "\n",
    "        # learned transition smoothing\n",
    "        self.trans_logits = nn.Parameter(torch.zeros(num_classes, num_classes))\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        z = self.encoder(x)\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            use_global = (self.global_every > 0) and ((i % self.global_every) == 0)\n",
    "            z = blk(z, mask, global_attn=use_global)\n",
    "        main_logits = self.head(z)\n",
    "        aux_logits  = self.aux_n1(z)\n",
    "        dur_logits  = self.aux_dur(z)\n",
    "        return main_logits, aux_logits, dur_logits\n",
    "\n",
    "\n",
    "# %% [CELL 4] Load checkpoint (EMA applied if available)\n",
    "\n",
    "DUR_EDGES = (2,5,10,20,40,80,160)\n",
    "DUR_BINS = len(DUR_EDGES) + 1\n",
    "\n",
    "model = HierSleepTransformerV5_1(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    d_model=384,\n",
    "    depth=12,\n",
    "    n_heads=8,\n",
    "    dur_bins=DUR_BINS,\n",
    "    window_size=64,\n",
    "    global_every=3\n",
    ").to(device)\n",
    "\n",
    "print(\"Model params (M):\", sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "\n",
    "CKPT_DIR = ROOT / \"checkpoints_hier_rope_seq_v5_1\"\n",
    "BEST_CKPT = CKPT_DIR / \"BEST_VAL_macroF1.pt\"\n",
    "assert BEST_CKPT.exists(), f\"Missing ckpt: {BEST_CKPT}\"\n",
    "print(\"Loading:\", BEST_CKPT)\n",
    "\n",
    "ckpt = torch.load(BEST_CKPT, map_location=\"cpu\")\n",
    "sd = ckpt[\"model_state\"]\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"Loaded model_state. missing:\", len(missing), \"| unexpected:\", len(unexpected))\n",
    "\n",
    "use_ema = bool(ckpt.get(\"use_ema\", False))\n",
    "ema_shadow = ckpt.get(\"ema_shadow\", None)\n",
    "\n",
    "if use_ema and isinstance(ema_shadow, dict) and len(ema_shadow) > 0:\n",
    "    with torch.no_grad():\n",
    "        curr = model.state_dict()\n",
    "        applied = 0\n",
    "        for k, v in ema_shadow.items():\n",
    "            if k in curr:\n",
    "                curr[k].copy_(v.to(curr[k].device).to(curr[k].dtype))\n",
    "                applied += 1\n",
    "        model.load_state_dict(curr, strict=False)\n",
    "    print(\"Applied EMA shadow tensors:\", applied)\n",
    "else:\n",
    "    print(\"EMA shadow not applied (missing/disabled).\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# %% [CELL 5] Full-night prediction per file (SHHS1 test)\n",
    "\n",
    "USE_LEARNED_SMOOTHING = True  # set False if you want raw softmax only\n",
    "\n",
    "def infer_subject_id(row):\n",
    "    if \"subject_id\" in row.index and pd.notna(row[\"subject_id\"]):\n",
    "        return str(row[\"subject_id\"])\n",
    "    return Path(row[\"npz_path\"]).stem\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_fullnight(npz_path: str):\n",
    "    d = np.load(npz_path, allow_pickle=True)\n",
    "    x = d[\"x\"].astype(np.float32)  # (E,T)\n",
    "    y = d[\"y\"].astype(np.int64)    # (E,)\n",
    "\n",
    "    keep = (y >= 0)\n",
    "    x = x[keep]\n",
    "    y = y[keep]\n",
    "\n",
    "    x = normalize_epochs_zscore(x, eps=1e-6, clip=10.0)\n",
    "\n",
    "    xb = torch.from_numpy(x).unsqueeze(0).unsqueeze(2).to(device)  # (1,E,1,T)\n",
    "    mb = torch.ones((1, xb.shape[1]), dtype=torch.bool, device=device)\n",
    "\n",
    "    main_logits, _, _ = model(xb, mb)\n",
    "    probs = torch.softmax(main_logits.float(), dim=-1)\n",
    "\n",
    "    if USE_LEARNED_SMOOTHING:\n",
    "        probs = apply_learned_smoothing_probs(probs, model.trans_logits)\n",
    "\n",
    "    pred = torch.argmax(probs, dim=-1).squeeze(0).cpu().numpy()\n",
    "    probs = probs.squeeze(0).cpu().numpy()\n",
    "\n",
    "    return y, pred, probs\n",
    "\n",
    "records = []\n",
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Predict SHHS1 TEST full nights\"):\n",
    "    npz_path = str(row[\"npz_path\"])\n",
    "    sid = infer_subject_id(row)\n",
    "    y_true, y_pred, probs = predict_fullnight(npz_path)\n",
    "    records.append({\n",
    "        \"subject_id\": sid,\n",
    "        \"npz_path\": npz_path,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"probs\": probs,\n",
    "    })\n",
    "\n",
    "print(\"Collected:\", len(records), \"subjects\")\n",
    "\n",
    "\n",
    "# %% [CELL 6] Hypnogram plotting + Night metrics + BlandAltman\n",
    "\n",
    "STAGE_NAMES = {0:\"W\", 1:\"N1\", 2:\"N2\", 3:\"N3\", 4:\"REM\"}\n",
    "HYPNO_YMAP = {0:4, 1:3, 2:2, 3:1, 4:0}  # W on top\n",
    "HYPNO_YTICKS = [4,3,2,1,0]\n",
    "HYPNO_YLABELS = [\"W\",\"N1\",\"N2\",\"N3\",\"REM\"]\n",
    "\n",
    "def compute_night_metrics(stage_seq):\n",
    "    stage_seq = np.asarray(stage_seq, dtype=np.int64)\n",
    "    E = len(stage_seq)\n",
    "    total_min = E * EPOCH_SEC / 60.0\n",
    "\n",
    "    is_sleep = (stage_seq != 0)\n",
    "    sleep_epochs = int(is_sleep.sum())\n",
    "    tst_min = sleep_epochs * EPOCH_SEC / 60.0\n",
    "    se_pct = 100.0 * (tst_min / total_min) if total_min > 0 else np.nan\n",
    "\n",
    "    if sleep_epochs == 0:\n",
    "        sol_min = total_min\n",
    "        waso_min = 0.0\n",
    "    else:\n",
    "        first_sleep = int(np.argmax(is_sleep))\n",
    "        sol_min = first_sleep * EPOCH_SEC / 60.0\n",
    "        waso_min = float(np.sum(stage_seq[first_sleep:] == 0) * EPOCH_SEC / 60.0)\n",
    "\n",
    "    def mins(sid): return float(np.sum(stage_seq == sid) * EPOCH_SEC / 60.0)\n",
    "\n",
    "    w_min, n1_min, n2_min, n3_min, rem_min = mins(0), mins(1), mins(2), mins(3), mins(4)\n",
    "\n",
    "    def pct(x): return 100.0 * (x / tst_min) if tst_min > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"TotalTime_min\": total_min,\n",
    "        \"TST_min\": tst_min,\n",
    "        \"SE_pct\": se_pct,\n",
    "        \"SOL_min\": sol_min,\n",
    "        \"WASO_min\": waso_min,\n",
    "        \"W_min\": w_min,\n",
    "        \"N1_min\": n1_min,\n",
    "        \"N2_min\": n2_min,\n",
    "        \"N3_min\": n3_min,\n",
    "        \"REM_min\": rem_min,\n",
    "        \"N1_pct\": pct(n1_min),\n",
    "        \"N2_pct\": pct(n2_min),\n",
    "        \"N3_pct\": pct(n3_min),\n",
    "        \"REM_pct\": pct(rem_min),\n",
    "    }\n",
    "\n",
    "def plot_hypnogram_pair(\n",
    "    y_true, y_pred, subject_id,\n",
    "    save_path=None,\n",
    "    max_hours=None,\n",
    "):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    E = len(y_true)\n",
    "    t_hours = (np.arange(E) * EPOCH_SEC) / 3600.0\n",
    "\n",
    "    if max_hours is not None:\n",
    "        keep = t_hours <= max_hours\n",
    "        y_true = y_true[keep]\n",
    "        y_pred = y_pred[keep]\n",
    "        t_hours = t_hours[keep]\n",
    "\n",
    "    yt = np.vectorize(HYPNO_YMAP.get)(y_true)\n",
    "    yp = np.vectorize(HYPNO_YMAP.get)(y_pred)\n",
    "\n",
    "    # Slightly shorter height for paper\n",
    "    fig, ax = plt.subplots(figsize=(14, 3.4))\n",
    "\n",
    "    ax.step(t_hours, yt, where=\"post\", linewidth=1.6, label=\"GT\")\n",
    "    ax.step(t_hours, yp, where=\"post\", linewidth=1.3, alpha=0.85, label=\"Pred\")\n",
    "\n",
    "\n",
    "    ax.set_yticks(HYPNO_YTICKS)\n",
    "    ax.set_yticklabels(HYPNO_YLABELS)\n",
    "    ax.set_ylim(-0.5, 4.5)\n",
    "\n",
    "    ax.set_xlabel(\"Time (hours)\")\n",
    "    ax.set_ylabel(\"Stage\")\n",
    "    ax.set_title(f\"SHHS1 TEST Hypnogram | {subject_id}\")\n",
    "\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # ---- KEY CHANGE: legend OUTSIDE ----\n",
    "    ax.legend(\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1.01, 0.5),\n",
    "        frameon=False\n",
    "    )\n",
    "\n",
    "    # Leave space on the right for legend\n",
    "    fig.tight_layout(rect=[0, 0, 0.88, 1])\n",
    "\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, dpi=400, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def bland_altman(gt, pred, title, xlab, ylab, save_path=None):\n",
    "    gt = np.asarray(gt, dtype=float)\n",
    "    pred = np.asarray(pred, dtype=float)\n",
    "    m = (gt + pred) / 2.0\n",
    "    d = (pred - gt)\n",
    "\n",
    "    bias = np.mean(d)\n",
    "    sd = np.std(d, ddof=1) if len(d) > 1 else 0.0\n",
    "    loa_low = bias - 1.96 * sd\n",
    "    loa_high = bias + 1.96 * sd\n",
    "\n",
    "    plt.figure(figsize=(6.5, 5.2))\n",
    "    plt.scatter(m, d, s=18, alpha=0.7)\n",
    "    plt.axhline(bias, linewidth=1.5)\n",
    "    plt.axhline(loa_low, linestyle=\"--\", linewidth=1.2)\n",
    "    plt.axhline(loa_high, linestyle=\"--\", linewidth=1.2)\n",
    "    plt.title(f\"{title}\\nBias={bias:.2f}, LoA=[{loa_low:.2f}, {loa_high:.2f}]\")\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=400)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "print(\"Plotting + metrics helpers ready.\")\n",
    "\n",
    "\n",
    "# %% [CELL 7] Build night-level dataframe (GT vs Pred) + errors\n",
    "\n",
    "rows = []\n",
    "for r in records:\n",
    "    gt = compute_night_metrics(r[\"y_true\"])\n",
    "    pr = compute_night_metrics(r[\"y_pred\"])\n",
    "\n",
    "    rows.append({\n",
    "        \"subject_id\": r[\"subject_id\"],\n",
    "        \"E\": len(r[\"y_true\"]),\n",
    "        \"TST_gt\": gt[\"TST_min\"],\n",
    "        \"TST_pred\": pr[\"TST_min\"],\n",
    "        \"SE_gt\": gt[\"SE_pct\"],\n",
    "        \"SE_pred\": pr[\"SE_pct\"],\n",
    "        \"SOL_gt\": gt[\"SOL_min\"],\n",
    "        \"SOL_pred\": pr[\"SOL_min\"],\n",
    "        \"WASO_gt\": gt[\"WASO_min\"],\n",
    "        \"WASO_pred\": pr[\"WASO_min\"],\n",
    "        \"N1_gt\": gt[\"N1_min\"],\n",
    "        \"N1_pred\": pr[\"N1_min\"],\n",
    "        \"N2_gt\": gt[\"N2_min\"],\n",
    "        \"N2_pred\": pr[\"N2_min\"],\n",
    "        \"N3_gt\": gt[\"N3_min\"],\n",
    "        \"N3_pred\": pr[\"N3_min\"],\n",
    "        \"REM_gt\": gt[\"REM_min\"],\n",
    "        \"REM_pred\": pr[\"REM_min\"],\n",
    "        \"REMpct_gt\": gt[\"REM_pct\"],\n",
    "        \"REMpct_pred\": pr[\"REM_pct\"],\n",
    "        \"N3pct_gt\": gt[\"N3_pct\"],\n",
    "        \"N3pct_pred\": pr[\"N3_pct\"],\n",
    "    })\n",
    "\n",
    "df_night = pd.DataFrame(rows)\n",
    "\n",
    "# add diffs + abs errors\n",
    "for k in [\"TST\",\"SE\",\"SOL\",\"WASO\",\"N1\",\"N2\",\"N3\",\"REM\",\"REMpct\",\"N3pct\"]:\n",
    "    df_night[f\"{k}_diff\"] = df_night[f\"{k}_pred\"] - df_night[f\"{k}_gt\"]\n",
    "    df_night[f\"{k}_abs\"]  = np.abs(df_night[f\"{k}_diff\"])\n",
    "\n",
    "display(df_night.head())\n",
    "\n",
    "print(\"\\nNight-level absolute error summary (mean ± std):\")\n",
    "for k in [\"TST\",\"SE\",\"SOL\",\"WASO\",\"N3\",\"REM\",\"N3pct\",\"REMpct\"]:\n",
    "    mu = df_night[f\"{k}_abs\"].mean()\n",
    "    sd = df_night[f\"{k}_abs\"].std(ddof=1)\n",
    "    print(f\"{k:6s} | MAE={mu:.2f} ± {sd:.2f}\")\n",
    "\n",
    "\n",
    "# %% [CELL 8] Save outputs (CSV + plots + sample hypnograms)\n",
    "\n",
    "OUT_BASE = ROOT / \"night_level_analysis_shhs1_test\"\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save table\n",
    "csv_path = OUT_BASE / \"night_metrics_gt_vs_pred.csv\"\n",
    "df_night.to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV:\", csv_path)\n",
    "\n",
    "# BlandAltman plots\n",
    "bland_altman(\n",
    "    df_night[\"TST_gt\"].values, df_night[\"TST_pred\"].values,\n",
    "    title=\"BlandAltman: Total Sleep Time (min)\",\n",
    "    xlab=\"Mean TST (min)\",\n",
    "    ylab=\"TST diff (Pred - GT, min)\",\n",
    "    save_path=OUT_BASE / \"bland_altman_TST.png\"\n",
    ")\n",
    "\n",
    "bland_altman(\n",
    "    df_night[\"SE_gt\"].values, df_night[\"SE_pred\"].values,\n",
    "    title=\"BlandAltman: Sleep Efficiency (%)\",\n",
    "    xlab=\"Mean SE (%)\",\n",
    "    ylab=\"SE diff (Pred - GT, %)\",\n",
    "    save_path=OUT_BASE / \"bland_altman_SE.png\"\n",
    ")\n",
    "\n",
    "bland_altman(\n",
    "    df_night[\"WASO_gt\"].values, df_night[\"WASO_pred\"].values,\n",
    "    title=\"BlandAltman: WASO (min)\",\n",
    "    xlab=\"Mean WASO (min)\",\n",
    "    ylab=\"WASO diff (Pred - GT, min)\",\n",
    "    save_path=OUT_BASE / \"bland_altman_WASO.png\"\n",
    ")\n",
    "\n",
    "bland_altman(\n",
    "    df_night[\"SOL_gt\"].values, df_night[\"SOL_pred\"].values,\n",
    "    title=\"BlandAltman: SOL (min)\",\n",
    "    xlab=\"Mean SOL (min)\",\n",
    "    ylab=\"SOL diff (Pred - GT, min)\",\n",
    "    save_path=OUT_BASE / \"bland_altman_SOL.png\"\n",
    ")\n",
    "\n",
    "print(\"Saved BlandAltman plots to:\", OUT_BASE)\n",
    "\n",
    "# save a few hypnograms (random + best/worst)\n",
    "def night_acc(y_true, y_pred):\n",
    "    return float((y_true == y_pred).mean()) if len(y_true) else np.nan\n",
    "\n",
    "acc_list = [(r[\"subject_id\"], night_acc(r[\"y_true\"], r[\"y_pred\"])) for r in records]\n",
    "acc_sorted = sorted(acc_list, key=lambda x: x[1])\n",
    "\n",
    "pick_ids = []\n",
    "pick_ids += [acc_sorted[0][0], acc_sorted[1][0]]               # 2 worst\n",
    "pick_ids += [acc_sorted[-1][0], acc_sorted[-2][0]]             # 2 best\n",
    "\n",
    "# plus 2 random not in list\n",
    "rng = np.random.RandomState(0)\n",
    "all_ids = [r[\"subject_id\"] for r in records]\n",
    "random_ids = [x for x in rng.choice(all_ids, size=min(20, len(all_ids)), replace=False) if x not in pick_ids]\n",
    "pick_ids += random_ids[:2]\n",
    "\n",
    "for sid in pick_ids:\n",
    "    r = next(rr for rr in records if rr[\"subject_id\"] == sid)\n",
    "    fig_path = OUT_BASE / f\"hypnogram_{sid}.png\"\n",
    "    plot_hypnogram_pair(r[\"y_true\"], r[\"y_pred\"], subject_id=sid, save_path=fig_path)\n",
    "\n",
    "print(\"Saved hypnogram PNGs:\", len(pick_ids), \"files\")\n",
    "print(\"Output folder:\", OUT_BASE)\n",
    "\n",
    "\n",
    "# %% [CELL 9] (Optional) Aggregate epoch-level metrics on SHHS1 test (for completeness)\n",
    "\n",
    "all_true = np.concatenate([r[\"y_true\"] for r in records])\n",
    "all_pred = np.concatenate([r[\"y_pred\"] for r in records])\n",
    "\n",
    "acc = accuracy_score(all_true, all_pred)\n",
    "mf1 = f1_score(all_true, all_pred, average=\"macro\")\n",
    "kappa = cohen_kappa_score(all_true, all_pred)\n",
    "cm = confusion_matrix(all_true, all_pred, labels=list(range(NUM_CLASSES)))\n",
    "\n",
    "f1_per = {LABELS[i]: float(f1_score((all_true==i).astype(int), (all_pred==i).astype(int)))\n",
    "          for i in range(NUM_CLASSES)}\n",
    "\n",
    "print(\"\\n===== SHHS1 TEST (epoch-level) =====\")\n",
    "print(f\"acc      : {acc:.4f}\")\n",
    "print(f\"macro_f1 : {mf1:.4f}\")\n",
    "print(f\"kappa    : {kappa:.4f}\")\n",
    "print(\"F1/class :\", f1_per)\n",
    "print(\"Confusion Matrix labels:\", [LABELS[i] for i in range(NUM_CLASSES)])\n",
    "print(cm)\n",
    "\n",
    "# Save epoch-level summary\n",
    "epoch_summary = {\n",
    "    \"acc\": float(acc),\n",
    "    \"macro_f1\": float(mf1),\n",
    "    \"kappa\": float(kappa),\n",
    "    \"f1_per_class\": f1_per,\n",
    "    \"cm\": cm.tolist(),\n",
    "    \"n_epochs\": int(len(all_true)),\n",
    "    \"checkpoint\": str(BEST_CKPT),\n",
    "    \"use_learned_smoothing\": bool(USE_LEARNED_SMOOTHING),\n",
    "}\n",
    "\n",
    "with open(OUT_BASE / \"epoch_level_summary.json\", \"w\") as f:\n",
    "    json.dump(epoch_summary, f, indent=2)\n",
    "\n",
    "print(\"Saved epoch-level summary:\", OUT_BASE / \"epoch_level_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea2bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT transition counts:\n",
      " [[107106   8562   5044     88   1322]\n",
      " [  2473  10576   6038     12    727]\n",
      " [  8345     91 199085  13256   2599]\n",
      " [  1014      9  12238  58165    136]\n",
      " [  3038    599   1078     11  71920]]\n",
      "Pred transition counts:\n",
      " [[100906  10937   3347     33    623]\n",
      " [  3269  16301   7830      2    726]\n",
      " [  7692    427 182738  11614   2521]\n",
      " [  1153      4  10354  68073    175]\n",
      " [  2685    484    800      4  80834]]\n",
      "Diff (Pred - GT) counts:\n",
      " [[ -6200   2375  -1697    -55   -699]\n",
      " [   796   5725   1792    -10     -1]\n",
      " [  -653    336 -16347  -1642    -78]\n",
      " [   139     -5  -1884   9908     39]\n",
      " [  -353   -115   -278     -7   8914]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/akbar1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 151 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/anaconda3/envs/akbar1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 151 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved transition matrices + plots into: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test\n"
     ]
    }
   ],
   "source": [
    "# %% [ADD-ON CELL 1] Transition matrices (GT vs Pred) + diff + normalized versions\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "C = NUM_CLASSES  # 5\n",
    "\n",
    "def transition_counts(seq, num_classes=5):\n",
    "    \"\"\"\n",
    "    seq: (E,) int labels in [0..C-1]\n",
    "    returns: (C,C) counts where M[i,j] = #transitions i->j\n",
    "    \"\"\"\n",
    "    seq = np.asarray(seq, dtype=np.int64)\n",
    "    if len(seq) < 2:\n",
    "        return np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    a = seq[:-1]\n",
    "    b = seq[1:]\n",
    "    M = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    np.add.at(M, (a, b), 1)\n",
    "    return M\n",
    "\n",
    "def row_normalize(M, eps=1e-12):\n",
    "    M = M.astype(np.float64)\n",
    "    rs = M.sum(axis=1, keepdims=True)\n",
    "    return M / (rs + eps)\n",
    "\n",
    "# --- aggregate over all SHHS1 test nights (records from the standalone script)\n",
    "M_gt = np.zeros((C, C), dtype=np.int64)\n",
    "M_pr = np.zeros((C, C), dtype=np.int64)\n",
    "\n",
    "for r in records:  # records = list of dicts with y_true/y_pred\n",
    "    M_gt += transition_counts(r[\"y_true\"], num_classes=C)\n",
    "    M_pr += transition_counts(r[\"y_pred\"], num_classes=C)\n",
    "\n",
    "M_diff = M_pr.astype(np.int64) - M_gt.astype(np.int64)\n",
    "\n",
    "M_gt_norm = row_normalize(M_gt)\n",
    "M_pr_norm = row_normalize(M_pr)\n",
    "M_diff_norm = M_pr_norm - M_gt_norm\n",
    "\n",
    "print(\"GT transition counts:\\n\", M_gt)\n",
    "print(\"Pred transition counts:\\n\", M_pr)\n",
    "print(\"Diff (Pred - GT) counts:\\n\", M_diff)\n",
    "\n",
    "def plot_matrix(M, title, labels=None, fmt=\".3f\", save_path=None):\n",
    "    labels = labels if labels is not None else [LABELS[i] for i in range(C)]\n",
    "    plt.figure(figsize=(6.2, 5.4))\n",
    "    plt.imshow(M, aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(range(C), labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(C), labels)\n",
    "    plt.xlabel(\"To\")\n",
    "    plt.ylabel(\"From\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # annotate\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            val = M[i, j]\n",
    "            if isinstance(val, (float, np.floating)):\n",
    "                s = format(val, fmt)\n",
    "            else:\n",
    "                s = str(int(val))\n",
    "            plt.text(j, i, s, ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=400)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "OUT_BASE = Path(OUT_BASE)  # ensure exists from your standalone script\n",
    "\n",
    "# Save matrices\n",
    "np.save(OUT_BASE / \"transitions_gt_counts.npy\", M_gt)\n",
    "np.save(OUT_BASE / \"transitions_pred_counts.npy\", M_pr)\n",
    "np.save(OUT_BASE / \"transitions_diff_counts.npy\", M_diff)\n",
    "\n",
    "np.save(OUT_BASE / \"transitions_gt_row_norm.npy\", M_gt_norm)\n",
    "np.save(OUT_BASE / \"transitions_pred_row_norm.npy\", M_pr_norm)\n",
    "np.save(OUT_BASE / \"transitions_diff_row_norm.npy\", M_diff_norm)\n",
    "\n",
    "# Plot (counts)\n",
    "plot_matrix(M_gt, \"Transition matrix (GT)  counts\", save_path=OUT_BASE / \"transition_GT_counts.png\")\n",
    "plot_matrix(M_pr, \"Transition matrix (Pred)  counts\", save_path=OUT_BASE / \"transition_Pred_counts.png\")\n",
    "plot_matrix(M_diff, \"Transition matrix (Pred - GT)  counts\", save_path=OUT_BASE / \"transition_Diff_counts.png\")\n",
    "\n",
    "# Plot (row-normalized)\n",
    "plot_matrix(M_gt_norm, \"Transition matrix (GT)  row-normalized\", fmt=\".3f\",\n",
    "            save_path=OUT_BASE / \"transition_GT_rowNorm.png\")\n",
    "plot_matrix(M_pr_norm, \"Transition matrix (Pred)  row-normalized\", fmt=\".3f\",\n",
    "            save_path=OUT_BASE / \"transition_Pred_rowNorm.png\")\n",
    "plot_matrix(M_diff_norm, \"Transition matrix (Pred - GT)  row-normalized\", fmt=\".3f\",\n",
    "            save_path=OUT_BASE / \"transition_Diff_rowNorm.png\")\n",
    "\n",
    "print(\"Saved transition matrices + plots into:\", OUT_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aba3432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>REMlat_gt_min</th>\n",
       "      <th>REMlat_pred_min</th>\n",
       "      <th>REMlat_diff_min</th>\n",
       "      <th>REMlat_abs_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shhs1-200018_v1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shhs1-200021_v1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shhs1-200035_v1</td>\n",
       "      <td>202.5</td>\n",
       "      <td>194.5</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shhs1-200039_v1</td>\n",
       "      <td>96.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shhs1-200043_v1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id  REMlat_gt_min  REMlat_pred_min  REMlat_diff_min  \\\n",
       "0  shhs1-200018_v1           42.5             88.0             45.5   \n",
       "1  shhs1-200021_v1           61.5             62.5              1.0   \n",
       "2  shhs1-200035_v1          202.5            194.5             -8.0   \n",
       "3  shhs1-200039_v1           96.5             96.5              0.0   \n",
       "4  shhs1-200043_v1           60.0             59.5             -0.5   \n",
       "\n",
       "   REMlat_abs_min  \n",
       "0            45.5  \n",
       "1             1.0  \n",
       "2             8.0  \n",
       "3             0.0  \n",
       "4             0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REM latency: valid nights = 540 / 548\n",
      "REM latency MAE = 14.10 ± 34.86 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/akbar1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 150 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/anaconda3/envs/akbar1/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 150 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test/rem_latency_gt_vs_pred.csv\n",
      "Saved: /data2/Akbar1/sleep_stages_Dibatic/shhs_sleepstaging_planA/night_level_analysis_shhs1_test/bland_altman_REM_latency.png\n"
     ]
    }
   ],
   "source": [
    "# %% [ADD-ON CELL 2] REM latency (GT vs Pred) + BlandAltman + summary + save\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "REM_ID = 4\n",
    "W_ID = 0\n",
    "\n",
    "def rem_latency_minutes(stage_seq):\n",
    "    \"\"\"\n",
    "    REM latency = (first REM epoch index - first sleep epoch index) * 0.5 minutes\n",
    "    If no sleep: return NaN\n",
    "    If no REM after sleep onset: return NaN (or you can set to total sleep time; keep NaN is cleaner)\n",
    "    \"\"\"\n",
    "    s = np.asarray(stage_seq, dtype=np.int64)\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    is_sleep = (s != W_ID)\n",
    "    if not np.any(is_sleep):\n",
    "        return np.nan\n",
    "\n",
    "    first_sleep = int(np.argmax(is_sleep))\n",
    "\n",
    "    rem_pos = np.where(s[first_sleep:] == REM_ID)[0]\n",
    "    if rem_pos.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    first_rem = first_sleep + int(rem_pos[0])\n",
    "    return (first_rem - first_sleep) * (EPOCH_SEC / 60.0)  # 0.5 min per epoch\n",
    "\n",
    "# compute per-night REM latency\n",
    "rem_rows = []\n",
    "for r in records:\n",
    "    gt_rl = rem_latency_minutes(r[\"y_true\"])\n",
    "    pr_rl = rem_latency_minutes(r[\"y_pred\"])\n",
    "    rem_rows.append({\n",
    "        \"subject_id\": r[\"subject_id\"],\n",
    "        \"REMlat_gt_min\": gt_rl,\n",
    "        \"REMlat_pred_min\": pr_rl,\n",
    "        \"REMlat_diff_min\": pr_rl - gt_rl if (np.isfinite(gt_rl) and np.isfinite(pr_rl)) else np.nan,\n",
    "        \"REMlat_abs_min\": abs(pr_rl - gt_rl) if (np.isfinite(gt_rl) and np.isfinite(pr_rl)) else np.nan,\n",
    "    })\n",
    "\n",
    "df_remlat = pd.DataFrame(rem_rows)\n",
    "\n",
    "# merge into df_night if you already created it\n",
    "if \"df_night\" in globals():\n",
    "    df_night = df_night.merge(df_remlat[[\"subject_id\",\"REMlat_gt_min\",\"REMlat_pred_min\",\"REMlat_diff_min\",\"REMlat_abs_min\"]],\n",
    "                              on=\"subject_id\", how=\"left\")\n",
    "    display(df_night[[\"subject_id\",\"REMlat_gt_min\",\"REMlat_pred_min\",\"REMlat_diff_min\",\"REMlat_abs_min\"]].head())\n",
    "\n",
    "# summary (only finite pairs)\n",
    "mask = np.isfinite(df_remlat[\"REMlat_gt_min\"].values) & np.isfinite(df_remlat[\"REMlat_pred_min\"].values)\n",
    "gt_vals = df_remlat.loc[mask, \"REMlat_gt_min\"].values\n",
    "pr_vals = df_remlat.loc[mask, \"REMlat_pred_min\"].values\n",
    "\n",
    "print(\"REM latency: valid nights =\", int(mask.sum()), \"/\", len(df_remlat))\n",
    "if mask.sum() > 0:\n",
    "    mae = np.mean(np.abs(pr_vals - gt_vals))\n",
    "    sd  = np.std(np.abs(pr_vals - gt_vals), ddof=1) if mask.sum() > 1 else 0.0\n",
    "    print(f\"REM latency MAE = {mae:.2f} ± {sd:.2f} minutes\")\n",
    "\n",
    "# BlandAltman using your existing function\n",
    "bland_altman(\n",
    "    gt_vals, pr_vals,\n",
    "    title=\"BlandAltman: REM latency (minutes)\",\n",
    "    xlab=\"Mean REM latency (min)\",\n",
    "    ylab=\"REM latency diff (Pred - GT, min)\",\n",
    "    save_path=OUT_BASE / \"bland_altman_REM_latency.png\"\n",
    ")\n",
    "\n",
    "# save CSV\n",
    "df_remlat.to_csv(OUT_BASE / \"rem_latency_gt_vs_pred.csv\", index=False)\n",
    "print(\"Saved:\", OUT_BASE / \"rem_latency_gt_vs_pred.csv\")\n",
    "print(\"Saved:\", OUT_BASE / \"bland_altman_REM_latency.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40f42d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: save_hypnogram_paper_overlay\n"
     ]
    }
   ],
   "source": [
    "# %% [CELL] Paper-style hypnogram (overlay) with legend outside\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_hypnogram_paper_overlay(\n",
    "    y_true, y_pred, out_png,\n",
    "    subject_id=None,\n",
    "    show_title=True,\n",
    "    legend_outside=True,\n",
    "    dpi=400\n",
    "):\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    y_pred = np.asarray(y_pred, dtype=int)\n",
    "    E = len(y_true)\n",
    "\n",
    "    t_hours = (np.arange(E) * EPOCH_SEC) / 3600.0\n",
    "\n",
    "    plt.figure(figsize=(10.5, 2.4))  # compact, paper-friendly\n",
    "\n",
    "    plt.step(t_hours, y_true, where=\"post\", linewidth=1.4, label=\"GT\")\n",
    "    plt.step(t_hours, y_pred, where=\"post\", linewidth=1.4, label=\"Pred\", alpha=0.9)\n",
    "\n",
    "    # Put W on top like your y-axis labels order: W, N1, N2, N3, REM\n",
    "    # Your numeric mapping is 0=W,1=N1,2=N2,3=N3,4=REM, so invert axis:\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.yticks([0,1,2,3,4], [\"W\",\"N1\",\"N2\",\"N3\",\"REM\"])\n",
    "\n",
    "    plt.xlabel(\"Time (hours)\")\n",
    "    plt.ylabel(\"Stage\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "\n",
    "    if show_title and subject_id is not None:\n",
    "        plt.title(f\"SHHS1 Test Hypnogram | {subject_id}\")\n",
    "\n",
    "    if legend_outside:\n",
    "        # Legend outside, no box inside the plot\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1.01, 0.5), frameon=False)\n",
    "        plt.tight_layout(rect=[0, 0, 0.86, 1])  # leave space on right\n",
    "    else:\n",
    "        # Or no legend at all:\n",
    "        # plt.legend().remove()\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.savefig(out_png, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Ready: save_hypnogram_paper_overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ea63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: regenerate for shhs1-201437_v1\n",
    "sid = \"shhs1-201437_v1\"\n",
    "r = next(rr for rr in records if rr[\"subject_id\"] == sid)\n",
    "\n",
    "save_hypnogram_paper_overlay(\n",
    "    r[\"y_true\"], r[\"y_pred\"],\n",
    "    out_png=OUT_BASE / f\"hypnogram_{sid}_paper.png\",\n",
    "    subject_id=sid,\n",
    "    show_title=False,          # <- remove title if you want\n",
    "    legend_outside=True        # <- legend outside\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19967c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
